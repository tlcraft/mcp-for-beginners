<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d72a1d9e9ad1a7cc8d40d05d546b5ca0",
  "translation_date": "2025-09-30T18:10:04+00:00",
  "source_file": "11-MCPServerHandsOnLabs/01-Architecture/README.md",
  "language_code": "el"
}
-->
# Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ ÎˆÎ½Î½Î¿Î¹ÎµÏ‚ Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚

## ğŸ¯ Î¤Î¹ ÎšÎ±Î»ÏÏ€Ï„ÎµÎ¹ Î‘Ï…Ï„ÏŒ Ï„Î¿ Î•ÏÎ³Î±ÏƒÏ„Î®ÏÎ¹Î¿

Î‘Ï…Ï„ÏŒ Ï„Î¿ ÎµÏÎ³Î±ÏƒÏ„Î®ÏÎ¹Î¿ Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Î¼Î¹Î± ÎµÎ¹Ï‚ Î²Î¬Î¸Î¿Ï‚ ÎµÎ¾ÎµÏÎµÏÎ½Î·ÏƒÎ· Ï„Ï‰Î½ Ï€ÏÎ¿Ï„ÏÏ€Ï‰Î½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚ Ï„Î¿Ï… MCP server, Ï„Ï‰Î½ Î±ÏÏ‡ÏÎ½ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÏÎ½ Ï„ÎµÏ‡Î½Î¹ÎºÎ®Ï‚ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Ï€Î¿Ï… Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶Î¿Ï…Î½ Î¹ÏƒÏ‡Ï…ÏÎ­Ï‚, ÎµÏ€ÎµÎºÏ„Î¬ÏƒÎ¹Î¼ÎµÏ‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ AI Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.

## Î•Ï€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·

Î— Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎµÎ½ÏŒÏ‚ MCP server Î­Ï„Î¿Î¹Î¼Î¿Ï… Î³Î¹Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î® Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€Î±Î¹Ï„ÎµÎ¯ Ï€ÏÎ¿ÏƒÎµÎºÏ„Î¹ÎºÎ­Ï‚ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ­Ï‚ Î±Ï€Î¿Ï†Î¬ÏƒÎµÎ¹Ï‚. Î‘Ï…Ï„ÏŒ Ï„Î¿ ÎµÏÎ³Î±ÏƒÏ„Î®ÏÎ¹Î¿ Î±Î½Î±Î»ÏÎµÎ¹ Ï„Î± Î²Î±ÏƒÎ¹ÎºÎ¬ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±, Ï„Î± Ï€ÏÏŒÏ„Ï…Ï€Î± ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï ÎºÎ±Î¹ Ï„Î¹Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚ Ï€Î¿Ï… ÎºÎ±Î¸Î¹ÏƒÏ„Î¿ÏÎ½ Ï„Î· Î»ÏÏƒÎ· Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Zava Retail Î¹ÏƒÏ‡Ï…ÏÎ®, Î±ÏƒÏ†Î±Î»Î® ÎºÎ±Î¹ ÎµÏ€ÎµÎºÏ„Î¬ÏƒÎ¹Î¼Î·.

Î˜Î± ÎºÎ±Ï„Î±Î½Î¿Î®ÏƒÎµÏ„Îµ Ï€ÏÏ‚ Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¬ ÎºÎ¬Î¸Îµ ÎµÏ€Î¯Ï€ÎµÎ´Î¿, Î³Î¹Î±Ï„Î¯ ÎµÏ€Î¹Î»Î­Ï‡Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ ÎºÎ±Î¹ Ï€ÏÏ‚ Î½Î± ÎµÏ†Î±ÏÎ¼ÏŒÏƒÎµÏ„Îµ Î±Ï…Ï„Î¬ Ï„Î± Ï€ÏÏŒÏ„Ï…Ï€Î± ÏƒÏ„Î¹Ï‚ Î´Î¹ÎºÎ­Ï‚ ÏƒÎ±Ï‚ Ï…Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹Ï‚ MCP.

## Î£Ï„ÏŒÏ‡Î¿Î¹ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚

ÎœÎ­Ï‡ÏÎ¹ Ï„Î¿ Ï„Î­Î»Î¿Ï‚ Î±Ï…Ï„Î¿Ï Ï„Î¿Ï… ÎµÏÎ³Î±ÏƒÏ„Î·ÏÎ¯Î¿Ï…, Î¸Î± Î¼Ï€Î¿ÏÎµÎ¯Ï„Îµ Î½Î±:

- **Î‘Î½Î±Î»ÏÏƒÎµÏ„Îµ** Ï„Î·Î½ Ï€Î¿Î»Ï…ÎµÏ€Î¯Ï€ÎµÎ´Î· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® ÎµÎ½ÏŒÏ‚ MCP server Î¼Îµ ÎµÎ½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- **ÎšÎ±Ï„Î±Î½Î¿Î®ÏƒÎµÏ„Îµ** Ï„Î¿Î½ ÏÏŒÎ»Î¿ ÎºÎ±Î¹ Ï„Î¹Ï‚ ÎµÏ…Î¸ÏÎ½ÎµÏ‚ ÎºÎ¬Î¸Îµ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ¿Ï ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î¿Ï…
- **Î£Ï‡ÎµÎ´Î¹Î¬ÏƒÎµÏ„Îµ** ÏƒÏ‡Î®Î¼Î±Ï„Î± Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï€Î¿Ï… Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶Î¿Ï…Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ MCP Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎµÎ½Î¿Î¹ÎºÎ¹Î±ÏƒÏ„ÏÎ½
- **Î¥Î»Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ„Îµ** ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ ÎºÎ±Î¹ Ï€ÏŒÏÏ‰Î½
- **Î•Ï†Î±ÏÎ¼ÏŒÏƒÎµÏ„Îµ** Ï€ÏÏŒÏ„Ï…Ï€Î± Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼Î¿Ï ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î®Ï‚ Î³Î¹Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î± Ï€Î±ÏÎ±Î³Ï‰Î³Î®Ï‚
- **Î‘Î¾Î¹Î¿Î»Î¿Î³Î®ÏƒÎµÏ„Îµ** Ï„Î± Ï€Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ Ï„Î± Î¼ÎµÎ¹Î¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÏÎ½ Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÎµÏ‰Î½

## ğŸ—ï¸ Î•Ï€Î¯Ï€ÎµÎ´Î± Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚ MCP Server

ÎŸ MCP server Î¼Î±Ï‚ Ï…Î»Î¿Ï€Î¿Î¹ÎµÎ¯ Î¼Î¹Î± **Ï€Î¿Î»Ï…ÎµÏ€Î¯Ï€ÎµÎ´Î· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®** Ï€Î¿Ï… Î´Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÎ¹ Ï„Î¹Ï‚ ÎµÏ…Î¸ÏÎ½ÎµÏ‚ ÎºÎ±Î¹ Ï€ÏÎ¿Î¬Î³ÎµÎ¹ Ï„Î· ÏƒÏ…Î½Ï„Î·ÏÎ·ÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±:

### Î•Ï€Î¯Ï€ÎµÎ´Î¿ 1: Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î ÏÏ‰Ï„Î¿ÎºÏŒÎ»Î»Î¿Ï… (FastMCP)
**Î•Ï…Î¸ÏÎ½Î·**: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±Ï‚ Ï€ÏÏ‰Ï„Î¿ÎºÏŒÎ»Î»Î¿Ï… MCP ÎºÎ±Î¹ Î´ÏÎ¿Î¼Î¿Î»ÏŒÎ³Î·ÏƒÎ· Î¼Î·Î½Ï…Î¼Î¬Ï„Ï‰Î½

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**Î’Î±ÏƒÎ¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬**:
- **Î£Ï…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ· Î ÏÏ‰Ï„Î¿ÎºÏŒÎ»Î»Î¿Ï…**: Î Î»Î®ÏÎ·Ï‚ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Ï€ÏÎ¿Î´Î¹Î±Î³ÏÎ±Ï†ÏÎ½ MCP
- **Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î¤ÏÏ€Ï‰Î½**: ÎœÎ¿Î½Ï„Î­Î»Î± Pydantic Î³Î¹Î± ÎµÏ€Î¹ÎºÏÏÏ‰ÏƒÎ· Î±Î¹Ï„Î·Î¼Î¬Ï„Ï‰Î½/Î±Ï€Î±Î½Ï„Î®ÏƒÎµÏ‰Î½
- **Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Async**: ÎœÎ· Î¼Ï€Î»Î¿ÎºÎ±ÏÎ¹ÏƒÎ¼Î­Î½Î¿ I/O Î³Î¹Î± Ï…ÏˆÎ·Î»Î® Ï„Î±Ï…Ï„ÏŒÏ‡ÏÎ¿Î½Î· ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
- **Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½**: Î¤Ï…Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½ÎµÏ‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½

### Î•Ï€Î¯Ï€ÎµÎ´Î¿ 2: Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÎ®Ï‚ Î›Î¿Î³Î¹ÎºÎ®Ï‚
**Î•Ï…Î¸ÏÎ½Î·**: Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÏÎ½ ÎºÎ±Î½ÏŒÎ½Ï‰Î½ ÎºÎ±Î¹ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ Î¼ÎµÏ„Î±Î¾Ï Ï€ÏÏ‰Ï„Î¿ÎºÏŒÎ»Î»Î¿Ï… ÎºÎ±Î¹ ÎµÏ€Î¹Ï€Î­Î´Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**Î’Î±ÏƒÎ¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬**:
- **Î•Ï€Î¹Î²Î¿Î»Î® Î•Ï€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÏÎ½ ÎšÎ±Î½ÏŒÎ½Ï‰Î½**: Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ· Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ ÏƒÎµ ÎºÎ±Ï„Î±ÏƒÏ„Î®Î¼Î±Ï„Î± ÎºÎ±Î¹ Î±ÎºÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- **Î£Ï…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒÏ‚ Î¥Ï€Î·ÏÎµÏƒÎ¹ÏÎ½**: ÎŸÏÏ‡Î®ÏƒÏ„ÏÏ‰ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï…Ï€Î·ÏÎµÏƒÎ¹ÏÎ½ AI
- **ÎœÎµÏ„Î±ÏƒÏ‡Î·Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**: ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Î±ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÏƒÎµ ÎµÏ€Î¹Ï‡ÎµÎ¹ÏÎ·ÏƒÎ¹Î±ÎºÎ­Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚
- **Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® Caching**: Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Î³Î¹Î± ÏƒÏ…Ï‡Î½Î¬ ÎµÏÏ‰Ï„Î®Î¼Î±Ï„Î±

### Î•Ï€Î¯Ï€ÎµÎ´Î¿ 3: Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
**Î•Ï…Î¸ÏÎ½Î·**: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, ÎµÎºÏ„Î­Î»ÎµÏƒÎ· ÎµÏÏ‰Ï„Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**Î’Î±ÏƒÎ¹ÎºÎ¬ Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬**:
- **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î Î¹ÏƒÎ¯Î½Î±Ï‚ Î£Ï…Î½Î´Î­ÏƒÎµÏ‰Î½**: Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï€ÏŒÏÏ‰Î½
- **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î£Ï…Î½Î±Î»Î»Î±Î³ÏÎ½**: Î£Ï…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ· ACID ÎºÎ±Î¹ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±Î½Î±ÎºÎ»Î®ÏƒÎµÏ‰Î½
- **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î•ÏÏ‰Ï„Î·Î¼Î¬Ï„Ï‰Î½**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· ÎºÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚
- **Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ· RLS**: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Ï€Î»Î±Î¹ÏƒÎ¯Î¿Ï… Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ ÏƒÎµ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Î³ÏÎ±Î¼Î¼Î®Ï‚

### Î•Ï€Î¯Ï€ÎµÎ´Î¿ 4: Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î¥Ï€Î¿Î´Î¿Î¼Î®Ï‚
**Î•Ï…Î¸ÏÎ½Î·**: Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î¿ÏÎ¹Î¶ÏŒÎ½Ï„Î¹Ï‰Î½ Î¸ÎµÎ¼Î¬Ï„Ï‰Î½ ÏŒÏ€Ï‰Ï‚ ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î®, Ï€Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· ÎºÎ±Î¹ Î´Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ·

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## ğŸ—„ï¸ Î ÏÏŒÏ„Ï…Ï€Î± Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï Î’Î¬ÏƒÎµÏ‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

Î¤Î¿ ÏƒÏ‡Î®Î¼Î± PostgreSQL Î¼Î±Ï‚ Ï…Î»Î¿Ï€Î¿Î¹ÎµÎ¯ Î±ÏÎºÎµÏ„Î¬ Î²Î±ÏƒÎ¹ÎºÎ¬ Ï€ÏÏŒÏ„Ï…Ï€Î± Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ MCP Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎµÎ½Î¿Î¹ÎºÎ¹Î±ÏƒÏ„ÏÎ½:

### 1. Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ Î£Ï‡Î®Î¼Î±Ï„Î¿Ï‚ Î Î¿Î»Î»Î±Ï€Î»ÏÎ½ Î•Î½Î¿Î¹ÎºÎ¹Î±ÏƒÏ„ÏÎ½

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**Î‘ÏÏ‡Î­Ï‚ Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï**:
- **Î£Ï…Î½Î­Ï€ÎµÎ¹Î± ÎÎ­Î½Ï‰Î½ ÎšÎ»ÎµÎ¹Î´Î¹ÏÎ½**: Î•Î¾Î±ÏƒÏ†Î¬Î»Î¹ÏƒÎ· Î±ÎºÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î¼ÎµÏ„Î±Î¾Ï Ï€Î¹Î½Î¬ÎºÏ‰Î½
- **Î”Î¹Î¬Î´Î¿ÏƒÎ· ID ÎšÎ±Ï„Î±ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚**: ÎšÎ¬Î¸Îµ Ï€Î¯Î½Î±ÎºÎ±Ï‚ ÏƒÏ…Î½Î±Î»Î»Î±Î³ÏÎ½ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ store_id
- **Î ÏÏ‰Ï„ÎµÏÎ¿Î½Ï„Î± ÎšÎ»ÎµÎ¹Î´Î¹Î¬ UUID**: Î Î±Î³ÎºÎ¿ÏƒÎ¼Î¯Ï‰Ï‚ Î¼Î¿Î½Î±Î´Î¹ÎºÎ¿Î¯ Î±Î½Î±Î³Î½Ï‰ÏÎ¹ÏƒÏ„Î¹ÎºÎ¿Î¯ Î³Î¹Î± ÎºÎ±Ï„Î±Î½ÎµÎ¼Î·Î¼Î­Î½Î± ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î±
- **Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î§ÏÎ¿Î½Î¹ÎºÏÎ½ Î£Î·Î¼ÎµÎ¯Ï‰Î½**: Î™ÏƒÏ„Î¿ÏÎ¹ÎºÏŒ Î±Î»Î»Î±Î³ÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

### 2. Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ ÏƒÎµ Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î“ÏÎ±Î¼Î¼Î®Ï‚

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**ÎŸÏ†Î­Î»Î· RLS**:
- **Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Î¦Î¹Î»Ï„ÏÎ¬ÏÎ¹ÏƒÎ¼Î±**: Î— Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎµÏ€Î¹Î²Î¬Î»Î»ÎµÎ¹ Î±Ï€Î¿Î¼ÏŒÎ½Ï‰ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- **Î‘Ï€Î»ÏŒÏ„Î·Ï„Î± Î•Ï†Î±ÏÎ¼Î¿Î³Î®Ï‚**: Î”ÎµÎ½ Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹ ÏƒÏÎ½Î¸ÎµÏ„ÎµÏ‚ WHERE clauses
- **Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± Î±Ï€ÏŒ Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®**: Î‘Î´ÏÎ½Î±Ï„Î¿ Î½Î± Î±Ï€Î¿ÎºÏ„Î·Î¸ÎµÎ¯ ÎºÎ±Ï„Î¬ Î»Î¬Î¸Î¿Ï‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î»Î¬Î¸Î¿Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
- **Î£Ï…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ· Î•Î»Î­Î³Ï‡Î¿Ï…**: Î£Î±Ï†Î® ÏŒÏÎ¹Î± Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

### 3. Î£Ï‡Î®Î¼Î± Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚ Vector

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## ğŸ”Œ Î ÏÏŒÏ„Ï…Ï€Î± Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ Î£Ï…Î½Î´Î­ÏƒÎµÏ‰Î½

Î— Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½ Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎµÎ¯Î½Î±Î¹ ÎºÏÎ¯ÏƒÎ¹Î¼Î· Î³Î¹Î± Ï„Î·Î½ Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Ï„Î¿Ï… MCP server:

### Î”Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ· Î Î¹ÏƒÎ¯Î½Î±Ï‚ Î£Ï…Î½Î´Î­ÏƒÎµÏ‰Î½

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎšÏÎºÎ»Î¿Ï… Î–Ï‰Î®Ï‚ Î ÏŒÏÏ‰Î½

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## ğŸ›¡ï¸ Î ÏÏŒÏ„Ï…Ï€Î± Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼Î¿Ï Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Î‘Î½Î¸ÎµÎºÏ„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚

ÎŸ Î¹ÏƒÏ‡Ï…ÏÏŒÏ‚ Ï‡ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶ÎµÎ¹ Î±Î¾Î¹ÏŒÏ€Î¹ÏƒÏ„Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… MCP server:

### Î™ÎµÏÎ±ÏÏ‡Î¹ÎºÎ¿Î¯ Î¤ÏÏ€Î¿Î¹ Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### Middleware Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼Î¿Ï Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## ğŸ“Š Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚

### Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ Î•ÏÏ‰Ï„Î·Î¼Î¬Ï„Ï‰Î½

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® Caching

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## ğŸ¯ Î’Î±ÏƒÎ¹ÎºÎ¬ Î£Ï…Î¼Ï€ÎµÏÎ¬ÏƒÎ¼Î±Ï„Î±

ÎœÎµÏ„Î¬ Ï„Î·Î½ Î¿Î»Î¿ÎºÎ»Î®ÏÏ‰ÏƒÎ· Î±Ï…Ï„Î¿Ï Ï„Î¿Ï… ÎµÏÎ³Î±ÏƒÏ„Î·ÏÎ¯Î¿Ï…, Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ±Ï„Î±Î½Î¿ÎµÎ¯Ï„Îµ:

âœ… **Î Î¿Î»Ï…ÎµÏ€Î¯Ï€ÎµÎ´Î· Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®**: Î ÏÏ‚ Î½Î± Î´Î¹Î±Ï‡Ï‰ÏÎ¯Î¶ÎµÏ„Îµ ÎµÏ…Î¸ÏÎ½ÎµÏ‚ ÏƒÏ„Î¿Î½ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ MCP server  
âœ… **Î ÏÏŒÏ„Ï…Ï€Î± Î’Î¬ÏƒÎµÏ‰Î½ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½**: Î£Ï‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒÏ‚ ÏƒÏ‡Î®Î¼Î±Ï„Î¿Ï‚ Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎµÎ½Î¿Î¹ÎºÎ¹Î±ÏƒÏ„ÏÎ½ ÎºÎ±Î¹ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ· RLS  
âœ… **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î£Ï…Î½Î´Î­ÏƒÎµÏ‰Î½**: Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Ï€Î¹ÏƒÎ¯Î½Î± ÎºÎ±Î¹ ÎºÏÎºÎ»Î¿Ï‚ Î¶Ï‰Î®Ï‚ Ï€ÏŒÏÏ‰Î½  
âœ… **Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î£Ï†Î±Î»Î¼Î¬Ï„Ï‰Î½**: Î™ÎµÏÎ±ÏÏ‡Î¹ÎºÎ¿Î¯ Ï„ÏÏ€Î¿Î¹ ÏƒÏ†Î±Î»Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Ï€ÏÏŒÏ„Ï…Ï€Î± Î±Î½Î¸ÎµÎºÏ„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚  
âœ… **Î’ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚**: Î Î±ÏÎ±ÎºÎ¿Î»Î¿ÏÎ¸Î·ÏƒÎ·, caching ÎºÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏÏ‰Ï„Î·Î¼Î¬Ï„Ï‰Î½  
âœ… **Î•Ï„Î¿Î¹Î¼ÏŒÏ„Î·Ï„Î± Î Î±ÏÎ±Î³Ï‰Î³Î®Ï‚**: Î˜Î­Î¼Î±Ï„Î± Ï…Ï€Î¿Î´Î¿Î¼Î®Ï‚ ÎºÎ±Î¹ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÎ¬ Ï€ÏÏŒÏ„Ï…Ï€Î±  

## ğŸš€ Î¤Î¹ Î‘ÎºÎ¿Î»Î¿Ï…Î¸ÎµÎ¯

Î£Ï…Î½ÎµÏ‡Î¯ÏƒÏ„Îµ Î¼Îµ **[Î•ÏÎ³Î±ÏƒÏ„Î®ÏÎ¹Î¿ 02: Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± ÎºÎ±Î¹ Î Î¿Î»Î»Î±Ï€Î»Î® Î•Î½Î¿Î¹ÎºÎ¯Î±ÏƒÎ·](../02-Security/README.md)** Î³Î¹Î± Î½Î± ÎµÎ¼Î²Î±Î¸ÏÎ½ÎµÏ„Îµ ÏƒÎµ:

- Î›ÎµÏ€Ï„Î¿Î¼Î­ÏÎµÎ¹ÎµÏ‚ Ï…Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ ÏƒÎµ Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î“ÏÎ±Î¼Î¼Î®Ï‚
- Î ÏÏŒÏ„Ï…Ï€Î± Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÎºÎ±Î¹ ÎµÎ¾Î¿Ï…ÏƒÎ¹Î¿Î´ÏŒÏ„Î·ÏƒÎ·Ï‚
- Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚ Î±Ï€Î¿Î¼ÏŒÎ½Ï‰ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÎµÎ½Î¿Î¹ÎºÎ¹Î±ÏƒÏ„ÏÎ½
- Î˜Î­Î¼Î±Ï„Î± ÎµÎ»Î­Î³Ï‡Î¿Ï… Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚ ÎºÎ±Î¹ ÏƒÏ…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ·Ï‚

## ğŸ“š Î ÏÏŒÏƒÎ¸ÎµÏ„Î¿Î¹ Î ÏŒÏÎ¿Î¹

### Î ÏÏŒÏ„Ï…Ï€Î± Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚
- [Clean Architecture in Python](https://github.com/cosmic-python/code) - Î ÏÏŒÏ„Ï…Ï€Î± Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚ Î³Î¹Î± ÎµÏ†Î±ÏÎ¼Î¿Î³Î­Ï‚ Python
- [Database Design Patterns](https://en.wikipedia.org/wiki/Database_design) - Î‘ÏÏ‡Î­Ï‚ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î¿Ï ÏƒÏ‡ÎµÏƒÎ¹Î±ÎºÏÎ½ Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- [Microservices Patterns](https://microservices.io/patterns/) - Î ÏÏŒÏ„Ï…Ï€Î± Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®Ï‚ Ï…Ï€Î·ÏÎµÏƒÎ¹ÏÎ½

### Î ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î± Î˜Î­Î¼Î±Ï„Î± PostgreSQL
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization) - ÎŸÎ´Î·Î³ÏŒÏ‚ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
- [Connection Pooling Best Practices](https://www.postgresql.org/docs/current/runtime-config-connection.html) - Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÏƒÏ…Î½Î´Î­ÏƒÎµÏ‰Î½
- [Query Planning and Optimization](https://www.postgresql.org/docs/current/planner-optimizer.html) - Î‘Ï€ÏŒÎ´Î¿ÏƒÎ· ÎµÏÏ‰Ï„Î·Î¼Î¬Ï„Ï‰Î½

### Î ÏÏŒÏ„Ï…Ï€Î± Async Python
- [AsyncIO Best Practices](https://docs.python.org/3/library/asyncio.html) - Î ÏÏŒÏ„Ï…Ï€Î± Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï Async
- [FastAPI Architecture](https://fastapi.tiangolo.com/advanced/) - Î£ÏÎ³Ï‡ÏÎ¿Î½Î· Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® web Python
- [Pydantic Models](https://pydantic-docs.helpmanual.io/) - Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ· ÎºÎ±Î¹ ÏƒÎµÎ¹ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½

---

**Î•Ï€ÏŒÎ¼ÎµÎ½Î¿**: ÎˆÏ„Î¿Î¹Î¼Î¿Î¹ Î½Î± ÎµÎ¾ÎµÏÎµÏ…Î½Î®ÏƒÎµÏ„Îµ Ï€ÏÏŒÏ„Ï…Ï€Î± Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±Ï‚; Î£Ï…Î½ÎµÏ‡Î¯ÏƒÏ„Îµ Î¼Îµ [Î•ÏÎ³Î±ÏƒÏ„Î®ÏÎ¹Î¿ 02: Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î± ÎºÎ±Î¹ Î Î¿Î»Î»Î±Ï€Î»Î® Î•Î½Î¿Î¹ÎºÎ¯Î±ÏƒÎ·](../02-Security/README.md)

---

**Î‘Ï€Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎµÏ…Î¸ÏÎ½Î·Ï‚**:  
Î‘Ï…Ï„ÏŒ Ï„Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ Î­Ï‡ÎµÎ¹ Î¼ÎµÏ„Î±Ï†ÏÎ±ÏƒÏ„ÎµÎ¯ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ Ï…Ï€Î·ÏÎµÏƒÎ¯Î± Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚ [Co-op Translator](https://github.com/Azure/co-op-translator). Î Î±ÏÏŒÎ»Î¿ Ï€Î¿Ï… ÎºÎ±Ï„Î±Î²Î¬Î»Î»Î¿Ï…Î¼Îµ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹ÎµÏ‚ Î³Î¹Î± Î±ÎºÏÎ¯Î²ÎµÎ¹Î±, Ï€Î±ÏÎ±ÎºÎ±Î»Î¿ÏÎ¼Îµ Î½Î± Î­Ï‡ÎµÏ„Îµ Ï…Ï€ÏŒÏˆÎ· ÏŒÏ„Î¹ Î¿Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î±Ï†ÏÎ¬ÏƒÎµÎ¹Ï‚ ÎµÎ½Î´Î­Ï‡ÎµÏ„Î±Î¹ Î½Î± Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ ÏƒÏ†Î¬Î»Î¼Î±Ï„Î± Î® Î±Î½Î±ÎºÏÎ¯Î²ÎµÎ¹ÎµÏ‚. Î¤Î¿ Ï€ÏÏ‰Ï„ÏŒÏ„Ï…Ï€Î¿ Î­Î³Î³ÏÎ±Ï†Î¿ ÏƒÏ„Î· Î¼Î·Ï„ÏÎ¹ÎºÎ® Ï„Î¿Ï… Î³Î»ÏÏƒÏƒÎ± Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¸ÎµÏ‰ÏÎµÎ¯Ï„Î±Î¹ Î· Î±Ï…Î¸ÎµÎ½Ï„Î¹ÎºÎ® Ï€Î·Î³Î®. Î“Î¹Î± ÎºÏÎ¯ÏƒÎ¹Î¼ÎµÏ‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯ÎµÏ‚, ÏƒÏ…Î½Î¹ÏƒÏ„Î¬Ï„Î±Î¹ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ® Î±Î½Î¸ÏÏÏ€Î¹Î½Î· Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·. Î”ÎµÎ½ Ï†Î­ÏÎ¿Ï…Î¼Îµ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Ï…Ï‡ÏŒÎ½ Ï€Î±ÏÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚ Î® ÎµÏƒÏ†Î±Î»Î¼Î­Î½ÎµÏ‚ ÎµÏÎ¼Î·Î½ÎµÎ¯ÎµÏ‚ Ï€Î¿Ï… Ï€ÏÎ¿ÎºÏÏ€Ï„Î¿Ï…Î½ Î±Ï€ÏŒ Ï„Î· Ï‡ÏÎ®ÏƒÎ· Î±Ï…Ï„Î®Ï‚ Ï„Î·Ï‚ Î¼ÎµÏ„Î¬Ï†ÏÎ±ÏƒÎ·Ï‚.