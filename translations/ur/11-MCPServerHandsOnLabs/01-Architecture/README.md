<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d72a1d9e9ad1a7cc8d40d05d546b5ca0",
  "translation_date": "2025-09-30T15:22:17+00:00",
  "source_file": "11-MCPServerHandsOnLabs/01-Architecture/README.md",
  "language_code": "ur"
}
-->
# Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©Û’ ØªØµÙˆØ±Ø§Øª

## ğŸ¯ Ø§Ø³ Ù„ÛŒØ¨ Ù…ÛŒÚº Ú©ÛŒØ§ Ø´Ø§Ù…Ù„ ÛÛ’

ÛŒÛ Ù„ÛŒØ¨ MCP Ø³Ø±ÙˆØ± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©Û’ Ù†Ù…ÙˆÙ†ÙˆÚºØŒ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ø§ØµÙˆÙ„ÙˆÚºØŒ Ø§ÙˆØ± ØªÚ©Ù†ÛŒÚ©ÛŒ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒÙˆÚº Ú©Ø§ ØªÙØµÛŒÙ„ÛŒ Ø¬Ø§Ø¦Ø²Û ÙØ±Ø§ÛÙ… Ú©Ø±ØªÛŒ ÛÛ’ Ø¬Ùˆ Ù…Ø¶Ø¨ÙˆØ·ØŒ Ù‚Ø§Ø¨Ù„ ØªÙˆØ³ÛŒØ¹ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø³Û’ Ø¬Ú‘ÛŒ AI Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù†Ø² Ú©Ùˆ Ø·Ø§Ù‚Øª Ø¯ÛŒØªÛŒ ÛÛŒÚºÛ”

## Ø¬Ø§Ø¦Ø²Û

ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾ Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± MCP Ø³Ø±ÙˆØ± Ø¨Ù†Ø§Ù†Ø§ Ù…Ø­ØªØ§Ø· Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±Ù„ ÙÛŒØµÙ„ÙˆÚº Ú©Ø§ ØªÙ‚Ø§Ø¶Ø§ Ú©Ø±ØªØ§ ÛÛ’Û” ÛŒÛ Ù„ÛŒØ¨ ÛÙ…Ø§Ø±Û’ Zava Retail Ø§ÛŒÙ†Ø§Ù„ÛŒÙ¹Ú©Ø³ Ø­Ù„ Ú©Ùˆ Ù…Ø¶Ø¨ÙˆØ·ØŒ Ù…Ø­ÙÙˆØ¸ØŒ Ø§ÙˆØ± Ù‚Ø§Ø¨Ù„ ØªÙˆØ³ÛŒØ¹ Ø¨Ù†Ø§Ù†Û’ ÙˆØ§Ù„Û’ Ú©Ù„ÛŒØ¯ÛŒ Ø§Ø¬Ø²Ø§Ø¡ØŒ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ù†Ù…ÙˆÙ†ÙˆÚºØŒ Ø§ÙˆØ± ØªÚ©Ù†ÛŒÚ©ÛŒ Ù¾ÛÙ„ÙˆØ¤Úº Ú©Ùˆ ØªÙˆÚ‘ Ú©Ø± Ø¨ÛŒØ§Ù† Ú©Ø±ØªÛŒ ÛÛ’Û”

Ø¢Ù¾ Ø³Ù…Ø¬Ú¾ÛŒÚº Ú¯Û’ Ú©Û ÛØ± Ù¾Ø±Øª Ú©ÛŒØ³Û’ ØªØ¹Ø§Ù…Ù„ Ú©Ø±ØªÛŒ ÛÛ’ØŒ Ù…Ø®ØµÙˆØµ Ù¹ÛŒÚ©Ù†Ø§Ù„ÙˆØ¬ÛŒØ² Ú©ÛŒÙˆÚº Ù…Ù†ØªØ®Ø¨ Ú©ÛŒ Ú¯Ø¦ÛŒÚºØŒ Ø§ÙˆØ± Ø§Ù† Ù†Ù…ÙˆÙ†ÙˆÚº Ú©Ùˆ Ø§Ù¾Ù†Û’ MCP Ù†ÙØ§Ø° Ù…ÛŒÚº Ú©ÛŒØ³Û’ Ù„Ø§Ú¯Ùˆ Ú©ÛŒØ§ Ø¬Ø§Ø¦Û’Û”

## Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù…Ù‚Ø§ØµØ¯

Ø§Ø³ Ù„ÛŒØ¨ Ú©Û’ Ø§Ø®ØªØªØ§Ù… ØªÚ©ØŒ Ø¢Ù¾ Ù‚Ø§Ø¨Ù„ ÛÙˆÚº Ú¯Û’:

- **ØªØ¬Ø²ÛŒÛ Ú©Ø±ÛŒÚº** MCP Ø³Ø±ÙˆØ± Ú©ÛŒ Ù¾Ø±Øª Ø¯Ø§Ø± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©Ùˆ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù† Ú©Û’ Ø³Ø§ØªÚ¾  
- **Ø³Ù…Ø¬Ú¾ÛŒÚº** ÛØ± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±Ù„ Ø¬Ø²Ùˆ Ú©Ø§ Ú©Ø±Ø¯Ø§Ø± Ø§ÙˆØ± Ø°Ù…Û Ø¯Ø§Ø±ÛŒØ§Úº  
- **ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Ø±ÛŒÚº** ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§Ø³Ú©ÛŒÙ…Û’ Ø¬Ùˆ Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ MCP Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù†Ø² Ú©Ùˆ Ø³Ù¾ÙˆØ±Ù¹ Ú©Ø±ØªÛ’ ÛÛŒÚº  
- **Ù†Ø§ÙØ° Ú©Ø±ÛŒÚº** Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„Ù†Ú¯ Ø§ÙˆØ± ÙˆØ³Ø§Ø¦Ù„ Ú©Û’ Ø§Ù†ØªØ¸Ø§Ù… Ú©ÛŒ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ  
- **Ù„Ø§Ú¯Ùˆ Ú©Ø±ÛŒÚº** Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ø³Ø³Ù¹Ù…Ø² Ú©Û’ Ù„ÛŒÛ’ Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ø§ÙˆØ± Ù„Ø§Ú¯Ù†Ú¯ Ú©Û’ Ù†Ù…ÙˆÙ†Û’  
- **ØªØ´Ø®ÛŒØµ Ú©Ø±ÛŒÚº** Ù…Ø®ØªÙ„Ù Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±Ù„ Ø·Ø±ÛŒÙ‚ÙˆÚº Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† ÙÙˆØ§Ø¦Ø¯ Ø§ÙˆØ± Ù†Ù‚ØµØ§Ù†Ø§Øª  

## ğŸ—ï¸ MCP Ø³Ø±ÙˆØ± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©ÛŒ Ù¾Ø±ØªÛŒÚº

ÛÙ…Ø§Ø±Ø§ MCP Ø³Ø±ÙˆØ± Ø§ÛŒÚ© **Ù¾Ø±Øª Ø¯Ø§Ø± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±** Ù†Ø§ÙØ° Ú©Ø±ØªØ§ ÛÛ’ Ø¬Ùˆ Ø®Ø¯Ø´Ø§Øª Ú©Ùˆ Ø§Ù„Ú¯ Ú©Ø±ØªØ§ ÛÛ’ Ø§ÙˆØ± Ø¯ÛŒÚ©Ú¾ Ø¨Ú¾Ø§Ù„ Ú©Ùˆ ÙØ±ÙˆØº Ø¯ÛŒØªØ§ ÛÛ’:

### Ù¾Ø±Øª 1: Ù¾Ø±ÙˆÙ¹ÙˆÚ©ÙˆÙ„ Ù¾Ø±Øª (FastMCP)
**Ø°Ù…Û Ø¯Ø§Ø±ÛŒ**: MCP Ù¾Ø±ÙˆÙ¹ÙˆÚ©ÙˆÙ„ Ú©Ù…ÛŒÙˆÙ†ÛŒÚ©ÛŒØ´Ù† Ø§ÙˆØ± Ù…ÛŒØ³Ø¬ Ø±ÙˆÙ¹Ù†Ú¯ Ú©Ùˆ Ø³Ù†Ø¨Ú¾Ø§Ù„Ù†Ø§

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**Ø§ÛÙ… Ø®ØµÙˆØµÛŒØ§Øª**:
- **Ù¾Ø±ÙˆÙ¹ÙˆÚ©ÙˆÙ„ Ú©ÛŒ ØªØ¹Ù…ÛŒÙ„**: Ù…Ú©Ù…Ù„ MCP ÙˆØ¶Ø§Ø­Øª Ú©ÛŒ Ø­Ù…Ø§ÛŒØª  
- **Ù¹Ø§Ø¦Ù¾ Ø³ÛŒÙÙ¹ÛŒ**: Ø¯Ø±Ø®ÙˆØ§Ø³Øª/Ø¬ÙˆØ§Ø¨ Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ Ú©Û’ Ù„ÛŒÛ’ Pydantic Ù…Ø§ÚˆÙ„Ø²  
- **Ø§ÛŒØ³ÛŒÙ†Ú© Ø³Ù¾ÙˆØ±Ù¹**: Ø²ÛŒØ§Ø¯Û ÛÙ… ÙˆÙ‚ØªÛŒ Ú©Û’ Ù„ÛŒÛ’ Ù†Ø§Ù† Ø¨Ù„Ø§Ú©Ù†Ú¯ I/O  
- **Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯**: Ù…Ø¹ÛŒØ§Ø±ÛŒ Ø§ÛŒØ±Ø± Ø¬ÙˆØ§Ø¨Ø§Øª  

### Ù¾Ø±Øª 2: Ø¨Ø²Ù†Ø³ Ù„Ø§Ø¬Ú© Ù¾Ø±Øª
**Ø°Ù…Û Ø¯Ø§Ø±ÛŒ**: Ø¨Ø²Ù†Ø³ Ø±ÙˆÙ„Ø² Ú©Ùˆ Ù†Ø§ÙØ° Ú©Ø±Ù†Ø§ Ø§ÙˆØ± Ù¾Ø±ÙˆÙ¹ÙˆÚ©ÙˆÙ„ Ø§ÙˆØ± ÚˆÛŒÙ¹Ø§ Ù¾Ø±ØªÙˆÚº Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† ÛÙ… Ø¢ÛÙ†Ú¯ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ù†Ø§

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**Ø§ÛÙ… Ø®ØµÙˆØµÛŒØ§Øª**:
- **Ø¨Ø²Ù†Ø³ Ø±ÙˆÙ„Ø² Ú©Ø§ Ù†ÙØ§Ø°**: Ø§Ø³Ù¹ÙˆØ± ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ Ø§ÙˆØ± ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø³Ø§Ù„Ù…ÛŒØª  
- **Ø³Ø±ÙˆØ³ ÛÙ… Ø¢ÛÙ†Ú¯ÛŒ**: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ø§ÙˆØ± AI Ø³Ø±ÙˆØ³Ø² Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† Ø¢Ø±Ú©Ø³Ù¹Ø±ÛŒØ´Ù†  
- **ÚˆÛŒÙ¹Ø§ Ú©ÛŒ ØªØ¨Ø¯ÛŒÙ„ÛŒ**: Ø®Ø§Ù… ÚˆÛŒÙ¹Ø§ Ú©Ùˆ Ø¨Ø²Ù†Ø³ Ø¨ØµÛŒØ±Øª Ù…ÛŒÚº ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±Ù†Ø§  
- **Ú©ÛŒÚ†Ù†Ú¯ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ**: Ø¨Ø§Ø± Ø¨Ø§Ø± Ú©ÛŒ Ø¬Ø§Ù†Û’ ÙˆØ§Ù„ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÙˆÚº Ú©Û’ Ù„ÛŒÛ’ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­  

### Ù¾Ø±Øª 3: ÚˆÛŒÙ¹Ø§ Ø§ÛŒÚ©Ø³ÛŒØ³ Ù¾Ø±Øª
**Ø°Ù…Û Ø¯Ø§Ø±ÛŒ**: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©Ù†Ú©Ø´Ù†Ø²ØŒ Ú©ÙˆØ¦Ø±ÛŒ Ú©Û’ Ù†ÙØ§Ø°ØŒ Ø§ÙˆØ± ÚˆÛŒÙ¹Ø§ Ù…ÛŒÙ¾Ù†Ú¯ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**Ø§ÛÙ… Ø®ØµÙˆØµÛŒØ§Øª**:
- **Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„Ù†Ú¯**: ÙˆØ³Ø§Ø¦Ù„ Ú©Û’ Ù…Ø¤Ø«Ø± Ø§Ù†ØªØ¸Ø§Ù…  
- **Ù¹Ø±Ø§Ù†Ø²ÛŒÚ©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹**: ACID ØªØ¹Ù…ÛŒÙ„ Ø§ÙˆØ± Ø±ÙˆÙ„ Ø¨ÛŒÚ© ÛÛŒÙ†ÚˆÙ„Ù†Ú¯  
- **Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­**: Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ù†Ú¯Ø±Ø§Ù†ÛŒ Ø§ÙˆØ± Ø§ØµÙ„Ø§Ø­  
- **RLS Ø§Ù†Ù¹ÛŒÚ¯Ø±ÛŒØ´Ù†**: Ø±Ùˆ Ù„ÛŒÙˆÙ„ Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø³ÛŒØ§Ù‚ Ùˆ Ø³Ø¨Ø§Ù‚ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…  

### Ù¾Ø±Øª 4: Ø§Ù†ÙØ±Ø§Ø³Ù¹Ø±Ú©Ú†Ø± Ù¾Ø±Øª
**Ø°Ù…Û Ø¯Ø§Ø±ÛŒ**: Ù„Ø§Ú¯Ù†Ú¯ØŒ Ù…Ø§Ù†ÛŒÙ¹Ø±Ù†Ú¯ØŒ Ø§ÙˆØ± Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù† Ø¬ÛŒØ³Û’ Ú©Ø±Ø§Ø³ Ú©Ù¹Ù†Ú¯ Ø®Ø¯Ø´Ø§Øª Ú©Ùˆ Ø³Ù†Ø¨Ú¾Ø§Ù„Ù†Ø§

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## ğŸ—„ï¸ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ù†Ù…ÙˆÙ†Û’

ÛÙ…Ø§Ø±Ø§ PostgreSQL Ø§Ø³Ú©ÛŒÙ…Û Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ MCP Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù†Ø² Ú©Û’ Ù„ÛŒÛ’ Ú©Ø¦ÛŒ Ø§ÛÙ… Ù†Ù…ÙˆÙ†Û’ Ù†Ø§ÙØ° Ú©Ø±ØªØ§ ÛÛ’:

### 1. Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ Ø§Ø³Ú©ÛŒÙ…Û ÚˆÛŒØ²Ø§Ø¦Ù†

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ø§ØµÙˆÙ„**:
- **ÙØ§Ø±Ù† Ú©ÛŒ Ú©Ù†Ø³Ø³Ù¹Ù†Ø³ÛŒ**: Ù¹ÛŒØ¨Ù„Ø² Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø³Ø§Ù„Ù…ÛŒØª Ú©Ùˆ ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†Ø§Ù†Ø§  
- **Ø§Ø³Ù¹ÙˆØ± Ø¢Ø¦ÛŒ ÚˆÛŒ Ú©Ø§ Ù¾Ú¾ÛŒÙ„Ø§Ø¤**: ÛØ± Ù¹Ø±Ø§Ù†Ø²ÛŒÚ©Ø´Ù†Ù„ Ù¹ÛŒØ¨Ù„ Ù…ÛŒÚº store_id Ø´Ø§Ù…Ù„ ÛÙˆØªØ§ ÛÛ’  
- **UUID Ù¾Ø±Ø§Ø¦Ù…Ø±ÛŒ Ú©ÛŒØ²**: ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯Û Ø³Ø³Ù¹Ù…Ø² Ú©Û’ Ù„ÛŒÛ’ Ø¹Ø§Ù„Ù…ÛŒ Ø·ÙˆØ± Ù¾Ø± Ù…Ù†ÙØ±Ø¯ Ø´Ù†Ø§Ø®Øª Ú©Ù†Ù†Ø¯Û  
- **Ù¹Ø§Ø¦Ù… Ø§Ø³Ù¹ÛŒÙ…Ù¾ Ù¹Ø±ÛŒÚ©Ù†Ú¯**: ØªÙ…Ø§Ù… ÚˆÛŒÙ¹Ø§ ØªØ¨Ø¯ÛŒÙ„ÛŒÙˆÚº Ú©Û’ Ù„ÛŒÛ’ Ø¢ÚˆÙ¹ Ù¹Ø±ÛŒÙ„  

### 2. Ø±Ùˆ Ù„ÛŒÙˆÙ„ Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ú©Ø§ Ù†ÙØ§Ø°

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**RLS Ú©Û’ ÙÙˆØ§Ø¦Ø¯**:
- **Ø®ÙˆØ¯Ú©Ø§Ø± ÙÙ„Ù¹Ø±Ù†Ú¯**: ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø¹Ù„ÛŒØ­Ø¯Ú¯ÛŒ Ú©Ùˆ Ù†Ø§ÙØ° Ú©Ø±ØªØ§ ÛÛ’  
- **Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù† Ú©ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ**: Ù¾ÛŒÚ†ÛŒØ¯Û WHERE Ú©Ù„Ø§Ø² Ú©ÛŒ Ø¶Ø±ÙˆØ±Øª Ù†ÛÛŒÚº  
- **ÚˆÛŒÙØ§Ù„Ù¹ Ú©Û’ Ø°Ø±ÛŒØ¹Û’ Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ**: ØºÙ„Ø· ÚˆÛŒÙ¹Ø§ ØªÚ© Ø­Ø§Ø¯Ø«Ø§ØªÛŒ Ø±Ø³Ø§Ø¦ÛŒ Ù†Ø§Ù…Ù…Ú©Ù†  
- **Ø¢ÚˆÙ¹ Ú©ÛŒ ØªØ¹Ù…ÛŒÙ„**: ÚˆÛŒÙ¹Ø§ ØªÚ© Ø±Ø³Ø§Ø¦ÛŒ Ú©ÛŒ ÙˆØ§Ø¶Ø­ Ø­Ø¯ÙˆØ¯  

### 3. ÙˆÛŒÚ©Ù¹Ø± Ø³Ø±Ú† Ø§Ø³Ú©ÛŒÙ…Û

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## ğŸ”Œ Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹ Ú©Û’ Ù†Ù…ÙˆÙ†Û’

MCP Ø³Ø±ÙˆØ± Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ù…Ø¤Ø«Ø± ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹ Ø§ÛÙ… ÛÛ’:

### Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„ Ú©Ù†ÙÛŒÚ¯Ø±ÛŒØ´Ù†

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### ÙˆØ³Ø§Ø¦Ù„ Ú©Û’ Ù„Ø§Ø¦Ù Ø³Ø§Ø¦ÛŒÚ©Ù„ Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ù…

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## ğŸ›¡ï¸ Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ø§ÙˆØ± Ù„Ú†Ú© Ú©Û’ Ù†Ù…ÙˆÙ†Û’

Ù…Ø¶Ø¨ÙˆØ· Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ MCP Ø³Ø±ÙˆØ± Ú©Û’ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¢Ù¾Ø±ÛŒØ´Ù† Ú©Ùˆ ÛŒÙ‚ÛŒÙ†ÛŒ Ø¨Ù†Ø§ØªÛŒ ÛÛ’:

### Ø¯Ø±Ø¬Û Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Û Ø§ÛŒØ±Ø± Ú©ÛŒ Ø§Ù‚Ø³Ø§Ù…

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯ Ù…ÚˆÙ„ ÙˆÛŒØ¦Ø±

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## ğŸ“Š Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­ Ú©ÛŒ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ

### Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ù†Ú¯Ø±Ø§Ù†ÛŒ

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### Ú©ÛŒÚ†Ù†Ú¯ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## ğŸ¯ Ø§ÛÙ… Ù†Ú©Ø§Øª

Ø§Ø³ Ù„ÛŒØ¨ Ú©Ùˆ Ù…Ú©Ù…Ù„ Ú©Ø±Ù†Û’ Ú©Û’ Ø¨Ø¹Ø¯ØŒ Ø¢Ù¾ Ú©Ùˆ Ø³Ù…Ø¬Ú¾Ù†Ø§ Ú†Ø§ÛÛŒÛ’:

âœ… **Ù¾Ø±Øª Ø¯Ø§Ø± Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±**: MCP Ø³Ø±ÙˆØ± ÚˆÛŒØ²Ø§Ø¦Ù† Ù…ÛŒÚº Ø®Ø¯Ø´Ø§Øª Ú©Ùˆ Ø§Ù„Ú¯ Ú©Ø±Ù†Û’ Ú©Ø§ Ø·Ø±ÛŒÙ‚Û  
âœ… **ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©Û’ Ù†Ù…ÙˆÙ†Û’**: Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ Ø§Ø³Ú©ÛŒÙ…Û ÚˆÛŒØ²Ø§Ø¦Ù† Ø§ÙˆØ± RLS Ú©Ø§ Ù†ÙØ§Ø°  
âœ… **Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹**: Ù…Ø¤Ø«Ø± Ù¾ÙˆÙ„Ù†Ú¯ Ø§ÙˆØ± ÙˆØ³Ø§Ø¦Ù„ Ú©Ø§ Ù„Ø§Ø¦Ù Ø³Ø§Ø¦ÛŒÚ©Ù„  
âœ… **Ø§ÛŒØ±Ø± ÛÛŒÙ†ÚˆÙ„Ù†Ú¯**: Ø¯Ø±Ø¬Û Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Û Ø§ÛŒØ±Ø± Ú©ÛŒ Ø§Ù‚Ø³Ø§Ù… Ø§ÙˆØ± Ù„Ú†Ú© Ú©Û’ Ù†Ù…ÙˆÙ†Û’  
âœ… **Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­**: Ù†Ú¯Ø±Ø§Ù†ÛŒØŒ Ú©ÛŒÚ†Ù†Ú¯ØŒ Ø§ÙˆØ± Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­  
âœ… **Ù¾Ø±ÙˆÚˆÚ©Ø´Ù† Ú©ÛŒ ØªÛŒØ§Ø±ÛŒ**: Ø§Ù†ÙØ±Ø§Ø³Ù¹Ø±Ú©Ú†Ø± Ú©Û’ Ø®Ø¯Ø´Ø§Øª Ø§ÙˆØ± Ø¢Ù¾Ø±ÛŒØ´Ù†Ù„ Ù†Ù…ÙˆÙ†Û’  

## ğŸš€ Ø¢Ú¯Û’ Ú©ÛŒØ§ ÛÛ’

**[Ù„ÛŒØ¨ 02: Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø§ÙˆØ± Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ø³ÛŒ](../02-Security/README.md)** Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§Ø±ÛŒ Ø±Ú©Ú¾ÛŒÚº ØªØ§Ú©Û Ú¯ÛØ±Ø§Ø¦ÛŒ Ù…ÛŒÚº Ø³ÛŒÚ©Ú¾ Ø³Ú©ÛŒÚº:

- Ø±Ùˆ Ù„ÛŒÙˆÙ„ Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ú©Û’ Ù†ÙØ§Ø° Ú©ÛŒ ØªÙØµÛŒÙ„Ø§Øª  
- ØªØµØ¯ÛŒÙ‚ Ø§ÙˆØ± Ø§Ø¬Ø§Ø²Øª Ú©Û’ Ù†Ù…ÙˆÙ†Û’  
- Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ù¹ ÚˆÛŒÙ¹Ø§ Ú©ÛŒ Ø¹Ù„ÛŒØ­Ø¯Ú¯ÛŒ Ú©ÛŒ Ø­Ú©Ù…Øª Ø¹Ù…Ù„ÛŒ  
- Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø¢ÚˆÙ¹ Ø§ÙˆØ± ØªØ¹Ù…ÛŒÙ„ Ú©Û’ Ù¾ÛÙ„Ùˆ  

## ğŸ“š Ø§Ø¶Ø§ÙÛŒ ÙˆØ³Ø§Ø¦Ù„

### Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©Û’ Ù†Ù…ÙˆÙ†Û’
- [Python Ù…ÛŒÚº Ú©Ù„ÛŒÙ† Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±](https://github.com/cosmic-python/code) - Python Ø§ÛŒÙ¾Ù„ÛŒÚ©ÛŒØ´Ù†Ø² Ú©Û’ Ù„ÛŒÛ’ Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±Ù„ Ù†Ù…ÙˆÙ†Û’  
- [ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ù†Ù…ÙˆÙ†Û’](https://en.wikipedia.org/wiki/Database_design) - Ø±ÛŒÙ„ÛŒØ´Ù†Ù„ ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ ÚˆÛŒØ²Ø§Ø¦Ù† Ú©Û’ Ø§ØµÙˆÙ„  
- [Ù…Ø§Ø¦ÛŒÚ©Ø±Ùˆ Ø³Ø±ÙˆØ³Ø² Ú©Û’ Ù†Ù…ÙˆÙ†Û’](https://microservices.io/patterns/) - Ø³Ø±ÙˆØ³ Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø± Ú©Û’ Ù†Ù…ÙˆÙ†Û’  

### PostgreSQL Ú©Û’ Ø¬Ø¯ÛŒØ¯ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
- [PostgreSQL Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­](https://wiki.postgresql.org/wiki/Performance_Optimization) - ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©ÛŒ Ø§ØµÙ„Ø§Ø­ Ú©Û’ Ø±ÛÙ†Ù…Ø§  
- [Ú©Ù†Ú©Ø´Ù† Ù¾ÙˆÙ„Ù†Ú¯ Ú©Û’ Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’](https://www.postgresql.org/docs/current/runtime-config-connection.html) - Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÙ†Ø¬Ù…Ù†Ù¹  
- [Ú©ÙˆØ¦Ø±ÛŒ Ù¾Ù„Ø§Ù†Ù†Ú¯ Ø§ÙˆØ± Ø§ØµÙ„Ø§Ø­](https://www.postgresql.org/docs/current/planner-optimizer.html) - Ú©ÙˆØ¦Ø±ÛŒ Ú©ÛŒ Ú©Ø§Ø±Ú©Ø±Ø¯Ú¯ÛŒ  

### Python Ø§ÛŒØ³ÛŒÙ†Ú© Ù†Ù…ÙˆÙ†Û’
- [AsyncIO Ú©Û’ Ø¨ÛØªØ±ÛŒÙ† Ø·Ø±ÛŒÙ‚Û’](https://docs.python.org/3/library/asyncio.html) - Ø§ÛŒØ³ÛŒÙ†Ú© Ù¾Ø±ÙˆÚ¯Ø±Ø§Ù…Ù†Ú¯ Ú©Û’ Ù†Ù…ÙˆÙ†Û’  
- [FastAPI Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±](https://fastapi.tiangolo.com/advanced/) - Ø¬Ø¯ÛŒØ¯ Python ÙˆÛŒØ¨ Ø¢Ø±Ú©ÛŒÙ¹ÛŒÚ©Ú†Ø±  
- [Pydantic Ù…Ø§ÚˆÙ„Ø²](https://pydantic-docs.helpmanual.io/) - ÚˆÛŒÙ¹Ø§ Ú©ÛŒ ØªÙˆØ«ÛŒÙ‚ Ø§ÙˆØ± Ø³ÛŒØ±ÛŒÙ„Ø§Ø¦Ø²ÛŒØ´Ù†  

---

**Ø§Ú¯Ù„Ø§**: Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ú©Û’ Ù†Ù…ÙˆÙ†ÙˆÚº Ú©Ùˆ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± ÛÛŒÚºØŸ [Ù„ÛŒØ¨ 02: Ø³ÛŒÚ©ÛŒÙˆØ±Ù¹ÛŒ Ø§ÙˆØ± Ù…Ù„Ù¹ÛŒ Ù¹ÛŒÙ†Ù†Ø³ÛŒ](../02-Security/README.md) Ú©Û’ Ø³Ø§ØªÚ¾ Ø¬Ø§Ø±ÛŒ Ø±Ú©Ú¾ÛŒÚºÛ”

---

**ÚˆØ³Ú©Ù„ÛŒÙ…Ø±**:  
ÛŒÛ Ø¯Ø³ØªØ§ÙˆÛŒØ² AI ØªØ±Ø¬Ù…Û Ø³Ø±ÙˆØ³ [Co-op Translator](https://github.com/Azure/co-op-translator) Ú©Ø§ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ú¯Ø¦ÛŒ ÛÛ’Û” ÛÙ… Ø¯Ø±Ø³ØªÚ¯ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ú©ÙˆØ´Ø´ Ú©Ø±ØªÛ’ ÛÛŒÚºØŒ Ù„ÛŒÚ©Ù† Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¢Ú¯Ø§Û Ø±ÛÛŒÚº Ú©Û Ø®ÙˆØ¯Ú©Ø§Ø± ØªØ±Ø¬Ù…Û’ Ù…ÛŒÚº ØºÙ„Ø·ÛŒØ§Úº ÛŒØ§ ØºÛŒØ± Ø¯Ø±Ø³ØªÛŒØ§Úº ÛÙˆ Ø³Ú©ØªÛŒ ÛÛŒÚºÛ” Ø§ØµÙ„ Ø¯Ø³ØªØ§ÙˆÛŒØ² Ú©Ùˆ Ø§Ø³ Ú©ÛŒ Ø§ØµÙ„ Ø²Ø¨Ø§Ù† Ù…ÛŒÚº Ù…Ø³ØªÙ†Ø¯ Ø°Ø±ÛŒØ¹Û Ø³Ù…Ø¬Ú¾Ø§ Ø¬Ø§Ù†Ø§ Ú†Ø§ÛÛŒÛ’Û” Ø§ÛÙ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ú©Û’ Ù„ÛŒÛ’ØŒ Ù¾ÛŒØ´Û ÙˆØ± Ø§Ù†Ø³Ø§Ù†ÛŒ ØªØ±Ø¬Ù…Û Ú©ÛŒ Ø³ÙØ§Ø±Ø´ Ú©ÛŒ Ø¬Ø§ØªÛŒ ÛÛ’Û” ÛÙ… Ø§Ø³ ØªØ±Ø¬Ù…Û’ Ú©Û’ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø³Û’ Ù¾ÛŒØ¯Ø§ ÛÙˆÙ†Û’ ÙˆØ§Ù„ÛŒ Ú©Ø³ÛŒ Ø¨Ú¾ÛŒ ØºÙ„Ø· ÙÛÙ…ÛŒ ÛŒØ§ ØºÙ„Ø· ØªØ´Ø±ÛŒØ­ Ú©Û’ Ø°Ù…Û Ø¯Ø§Ø± Ù†ÛÛŒÚº ÛÛŒÚºÛ”