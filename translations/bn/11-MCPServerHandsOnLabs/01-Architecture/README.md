<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d72a1d9e9ad1a7cc8d40d05d546b5ca0",
  "translation_date": "2025-09-30T15:23:15+00:00",
  "source_file": "11-MCPServerHandsOnLabs/01-Architecture/README.md",
  "language_code": "bn"
}
-->
# ржорзВрж▓ рж╕рзНржерж╛ржкрждрзНржп ржзрж╛рж░ржгрж╛

## ЁЯОп ржПржЗ рж▓рзНржпрж╛ржмрзЗ ржХрзА рж╢рзЗржЦрж╛ржирзЛ рж╣ржмрзЗ

ржПржЗ рж▓рзНржпрж╛ржмржЯрж┐ MCP рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ рж╕рзНржерж╛ржкрждрзНржп ржкрзНржпрж╛ржЯрж╛рж░рзНржи, ржбрж╛ржЯрж╛ржмрзЗрж╕ ржбрж┐ржЬрж╛ржЗржирзЗрж░ ржирзАрждрж┐ржорж╛рж▓рж╛ ржПржмржВ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА, рж╕рзНржХрзЗрж▓ржпрзЛржЧрзНржп ржбрж╛ржЯрж╛ржмрзЗрж╕-ржЗржирзНржЯрж┐ржЧрзНрж░рзЗржЯрзЗржб AI ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи рждрзИрж░рж┐рж░ ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧржд ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрзМрж╢рж▓ржЧрзБрж▓рзЛрж░ ржЧржнрзАрж░ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржкрзНрж░ржжрж╛ржи ржХрж░рзЗред

## рж╕ржВржХрзНрж╖рж┐ржкрзНржд ржмрж┐ржмрж░ржг

ржбрж╛ржЯрж╛ржмрзЗрж╕ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржирзЗрж░ рж╕рж╛ржерзЗ ржПржХржЯрж┐ ржкрзНрж░рзЛржбрж╛ржХрж╢ржи-рж░рзЗржбрж┐ MCP рж╕рж╛рж░рзНржнрж╛рж░ рждрзИрж░рж┐ ржХрж░рждрзЗ рж╕ржарж┐ржХ рж╕рзНржерж╛ржкрждрзНржп рж╕рж┐ржжрзНржзрж╛ржирзНржд ржирзЗржУржпрж╝рж╛ ржЕрждрзНржпржирзНржд ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржгред ржПржЗ рж▓рзНржпрж╛ржмржЯрж┐ ржЖржорж╛ржжрзЗрж░ Zava Retail ржЕрзНржпрж╛ржирж╛рж▓рж┐ржЯрж┐ржХрзНрж╕ рж╕ржорж╛ржзрж╛ржиржХрзЗ рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА, ржирж┐рж░рж╛ржкржж ржПржмржВ рж╕рзНржХрзЗрж▓ржпрзЛржЧрзНржп ржХрж░рж╛рж░ ржЬржирзНржп ржкрзНрж░ржпрж╝рзЛржЬржирзАржпрж╝ ржорзВрж▓ ржЙржкрж╛ржжрж╛ржи, ржбрж┐ржЬрж╛ржЗржи ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржПржмржВ ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧржд ржмрж┐ржмрзЗржЪржирж╛ржЧрзБрж▓рзЛ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг ржХрж░рзЗред

ржЖржкржирж┐ рж╢рж┐ржЦржмрзЗржи ржХрзАржнрж╛ржмрзЗ ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзНрждрж░ ржПржХрзЗ ржЕржкрж░рзЗрж░ рж╕рж╛ржерзЗ ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рзЗ, ржХрзЗржи ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржкрзНрж░ржпрзБржХрзНрждрж┐ржЧрзБрж▓рзЛ ржмрзЗржЫрзЗ ржирзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрзЗ ржПржмржВ ржХрзАржнрж╛ржмрзЗ ржПржЗ ржкрзНржпрж╛ржЯрж╛рж░рзНржиржЧрзБрж▓рзЛ ржЖржкржирж╛рж░ ржирж┐ржЬрж╕рзНржм MCP ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржирзЗ ржкрзНрж░ржпрж╝рзЛржЧ ржХрж░ржмрзЗржиред

## рж╢рзЗржЦрж╛рж░ рж▓ржХрзНрж╖рзНржп

ржПржЗ рж▓рзНржпрж╛ржм рж╢рзЗрж╖рзЗ ржЖржкржирж┐:

- **ржмрж┐рж╢рзНрж▓рзЗрж╖ржг** ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи MCP рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ рж╕рзНрждрж░ржпрзБржХрзНржд рж╕рзНржерж╛ржкрждрзНржп ржПржмржВ ржбрж╛ржЯрж╛ржмрзЗрж╕ ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи
- **ржмрзЛржЭрждрзЗ** ржкрж╛рж░ржмрзЗржи ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзНржерж╛ржкрждрзНржп ржЙржкрж╛ржжрж╛ржирзЗрж░ ржнрзВржорж┐ржХрж╛ ржПржмржВ ржжрж╛ржпрж╝рж┐рждрзНржм
- **ржбрж┐ржЬрж╛ржЗржи** ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНржЯ MCP ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи рж╕ржорж░рзНржержиржХрж╛рж░рзА ржбрж╛ржЯрж╛ржмрзЗрж╕ рж╕рзНржХрж┐ржорж╛
- **ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи** ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи ржХрж╛ржирзЗржХрж╢ржи ржкрзБрж▓рж┐ржВ ржПржмржВ рж░рж┐рж╕рзЛрж░рзНрж╕ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржХрзМрж╢рж▓
- **ржкрзНрж░ржпрж╝рзЛржЧ** ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи ржкрзНрж░рзЛржбрж╛ржХрж╢ржи рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржПржмржВ рж▓ржЧрж┐ржВ ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- **ржорзВрж▓рзНржпрж╛ржпрж╝ржи** ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи ржмрж┐ржнрж┐ржирзНржи рж╕рзНржерж╛ржкрждрзНржп ржкржжрзНржзрждрж┐рж░ ржоржзрзНржпрзЗ ржЯрзНрж░рзЗржб-ржЕржл

## ЁЯПЧя╕П MCP рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ рж╕рзНржерж╛ржкрждрзНржп рж╕рзНрждрж░

ржЖржорж╛ржжрзЗрж░ MCP рж╕рж╛рж░рзНржнрж╛рж░ ржПржХржЯрж┐ **рж╕рзНрждрж░ржпрзБржХрзНржд рж╕рзНржерж╛ржкрждрзНржп** ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржпрж╛ рж░ржХрзНрж╖ржгрж╛ржмрзЗржХрзНрж╖ржгржпрзЛржЧрзНржпрждрж╛ ржмрж╛ржбрж╝рж╛ржпрж╝ ржПржмржВ ржжрж╛ржпрж╝рж┐рждрзНржм ржкрзГржержХ ржХрж░рзЗ:

### рж╕рзНрждрж░ рзз: ржкрзНрж░рзЛржЯрзЛржХрж▓ рж╕рзНрждрж░ (FastMCP)
**ржжрж╛ржпрж╝рж┐рждрзНржм**: MCP ржкрзНрж░рзЛржЯрзЛржХрж▓ ржпрзЛржЧрж╛ржпрзЛржЧ ржПржмржВ ржмрж╛рж░рзНрждрж╛ рж░рж╛ржЙржЯрж┐ржВ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рж╛

```python
# FastMCP server setup
from fastmcp import FastMCP

mcp = FastMCP("Zava Retail Analytics")

# Tool registration with type safety
@mcp.tool()
async def execute_sales_query(
    ctx: Context,
    postgresql_query: Annotated[str, Field(description="Well-formed PostgreSQL query")]
) -> str:
    """Execute PostgreSQL queries with Row Level Security."""
    return await query_executor.execute(postgresql_query, ctx)
```

**ржорзВрж▓ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**:
- **ржкрзНрж░рзЛржЯрзЛржХрж▓ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп**: MCP рж╕рзНржкрзЗрж╕рж┐ржлрж┐ржХрзЗрж╢ржирзЗрж░ ржкрзВрж░рзНржг рж╕ржорж░рзНржержи
- **ржЯрж╛ржЗржк рж╕рзБрж░ржХрзНрж╖рж╛**: ржЕржирзБрж░рзЛржз/ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛ ржпрж╛ржЪрж╛ржЗржпрж╝рзЗрж░ ржЬржирзНржп Pydantic ржоржбрзЗрж▓
- **ржЕрзНржпрж╛рж╕рж┐ржЩрзНржХ рж╕рж╛ржкрзЛрж░рзНржЯ**: ржЙржЪрзНржЪ ржХржиржХрж╛рж░рзЗржирзНрж╕рж┐рж░ ржЬржирзНржп ржиржи-ржмрзНрж▓ржХрж┐ржВ I/O
- **рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛**: ржорж╛ржиржХ рждрзНрж░рзБржЯрж┐ ржкрзНрж░рждрж┐ржХрзНрж░рж┐ржпрж╝рж╛

### рж╕рзНрждрж░ рзи: ржмрж┐ржЬржирзЗрж╕ рж▓ржЬрж┐ржХ рж╕рзНрждрж░
**ржжрж╛ржпрж╝рж┐рждрзНржм**: ржмрж┐ржЬржирзЗрж╕ ржирж┐ржпрж╝ржо ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржПржмржВ ржкрзНрж░рзЛржЯрзЛржХрж▓ ржУ ржбрж╛ржЯрж╛ рж╕рзНрждрж░рзЗрж░ ржоржзрзНржпрзЗ рж╕ржоржирзНржмржпрж╝ ржХрж░рж╛

```python
class SalesAnalyticsService:
    """Business logic for retail analytics operations."""
    
    async def get_store_performance(
        self, 
        store_id: str, 
        time_period: str
    ) -> Dict[str, Any]:
        """Calculate store performance metrics."""
        
        # Validate business rules
        if not self._validate_store_access(store_id):
            raise UnauthorizedError("Access denied for store")
        
        # Coordinate data retrieval
        sales_data = await self.db_provider.get_sales_data(store_id, time_period)
        metrics = self._calculate_metrics(sales_data)
        
        return {
            "store_id": store_id,
            "period": time_period,
            "metrics": metrics,
            "insights": self._generate_insights(metrics)
        }
```

**ржорзВрж▓ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**:
- **ржмрж┐ржЬржирзЗрж╕ ржирж┐ржпрж╝ржо ржкрзНрж░ржпрж╝рзЛржЧ**: рж╕рзНржЯрзЛрж░ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржпрж╛ржЪрж╛ржЗ ржПржмржВ ржбрж╛ржЯрж╛ ржЕржЦржгрзНржбрждрж╛
- **рж╕рж╛рж░рзНржнрж┐рж╕ рж╕ржоржирзНржмржпрж╝**: ржбрж╛ржЯрж╛ржмрзЗрж╕ ржПржмржВ AI рж╕рж╛рж░рзНржнрж┐рж╕рзЗрж░ ржоржзрзНржпрзЗ ржЕрж░рзНржХрзЗрж╕рзНржЯрзНрж░рзЗрж╢ржи
- **ржбрж╛ржЯрж╛ рж░рзВржкрж╛ржирзНрждрж░**: ржХрж╛ржБржЪрж╛ ржбрж╛ржЯрж╛ржХрзЗ ржмрж┐ржЬржирзЗрж╕ ржЗржирж╕рж╛ржЗржЯрзЗ рж░рзВржкрж╛ржирзНрждрж░ ржХрж░рж╛
- **ржХрзНржпрж╛рж╢рж┐ржВ ржХрзМрж╢рж▓**: ржШржи ржШржи ржкрзНрж░рж╢рзНржирзЗрж░ ржЬржирзНржп ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи

### рж╕рзНрждрж░ рзй: ржбрж╛ржЯрж╛ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ рж╕рзНрждрж░
**ржжрж╛ржпрж╝рж┐рждрзНржм**: ржбрж╛ржЯрж╛ржмрзЗрж╕ рж╕ржВржпрзЛржЧ ржкрж░рж┐ржЪрж╛рж▓ржирж╛, ржкрзНрж░рж╢рзНржи ржХрж╛рж░рзНржпржХрж░ ржХрж░рж╛ ржПржмржВ ржбрж╛ржЯрж╛ ржорзНржпрж╛ржкрж┐ржВ

```python
class PostgreSQLProvider:
    """Data access layer for PostgreSQL operations."""
    
    def __init__(self, connection_config: Dict[str, Any]):
        self.connection_pool: Optional[Pool] = None
        self.config = connection_config
    
    async def execute_query(
        self, 
        query: str, 
        rls_user_id: str
    ) -> List[Dict[str, Any]]:
        """Execute query with RLS context."""
        
        async with self.connection_pool.acquire() as conn:
            # Set RLS context
            await conn.execute(
                "SELECT set_config('app.current_rls_user_id', $1, false)",
                rls_user_id
            )
            
            # Execute query with timeout
            try:
                rows = await asyncio.wait_for(
                    conn.fetch(query),
                    timeout=30.0
                )
                return [dict(row) for row in rows]
            except asyncio.TimeoutError:
                raise QueryTimeoutError("Query execution exceeded timeout")
```

**ржорзВрж▓ ржмрзИрж╢рж┐рж╖рзНржЯрзНржп**:
- **ржХрж╛ржирзЗржХрж╢ржи ржкрзБрж▓рж┐ржВ**: ржжржХрзНрж╖ рж░рж┐рж╕рзЛрж░рзНрж╕ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ
- **рж▓рзЗржиржжрзЗржи ржкрж░рж┐ржЪрж╛рж▓ржирж╛**: ACID рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржПржмржВ рж░рзЛрж▓ржмрзНржпрж╛ржХ рж╣рзНржпрж╛ржирзНржбрж▓рж┐ржВ
- **ржкрзНрж░рж╢рзНржи ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржоржирж┐ржЯрж░рж┐ржВ ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи
- **RLS ржЗржирзНржЯрж┐ржЧрзНрж░рзЗрж╢ржи**: рж░рзЛ-рж▓рзЗржнрзЗрж▓ рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ ржХржиржЯрзЗржХрзНрж╕ржЯ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ

### рж╕рзНрждрж░ рзк: ржЗржиржлрзНрж░рж╛рж╕рзНржЯрзНрж░рж╛ржХржЪрж╛рж░ рж╕рзНрждрж░
**ржжрж╛ржпрж╝рж┐рждрзНржм**: рж▓ржЧрж┐ржВ, ржоржирж┐ржЯрж░рж┐ржВ ржПржмржВ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржирзЗрж░ ржорждрзЛ ржХрзНрж░рж╕-ржХрж╛ржЯрж┐ржВ ржмрж┐рж╖ржпрж╝ржЧрзБрж▓рзЛ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржХрж░рж╛

```python
class InfrastructureManager:
    """Infrastructure concerns management."""
    
    def __init__(self):
        self.logger = self._setup_logging()
        self.metrics = self._setup_metrics()
        self.config = self._load_configuration()
    
    def _setup_logging(self) -> Logger:
        """Configure structured logging."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('mcp_server.log')
            ]
        )
        return logging.getLogger(__name__)
    
    async def track_query_execution(
        self, 
        query_type: str, 
        duration: float, 
        success: bool
    ):
        """Track query performance metrics."""
        self.metrics.counter('query_total').labels(
            type=query_type,
            status='success' if success else 'error'
        ).inc()
        
        self.metrics.histogram('query_duration').labels(
            type=query_type
        ).observe(duration)
```

## ЁЯЧДя╕П ржбрж╛ржЯрж╛ржмрзЗрж╕ ржбрж┐ржЬрж╛ржЗржи ржкрзНржпрж╛ржЯрж╛рж░рзНржи

ржЖржорж╛ржжрзЗрж░ PostgreSQL рж╕рзНржХрж┐ржорж╛ ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНржЯ MCP ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржХржпрж╝рзЗржХржЯрж┐ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░рзЗ:

### рзз. ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНржЯ рж╕рзНржХрж┐ржорж╛ ржбрж┐ржЬрж╛ржЗржи

```sql
-- Core retail entities with store-based partitioning
CREATE TABLE retail.stores (
    store_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    location VARCHAR(200) NOT NULL,
    manager_id UUID NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.customers (
    customer_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    store_id UUID REFERENCES retail.stores(store_id),
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) UNIQUE,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE retail.orders (
    order_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_id UUID REFERENCES retail.customers(customer_id),
    store_id UUID REFERENCES retail.stores(store_id),
    order_date TIMESTAMP DEFAULT NOW(),
    total_amount DECIMAL(10,2) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending'
);
```

**ржбрж┐ржЬрж╛ржЗржи ржирзАрждрж┐ржорж╛рж▓рж╛**:
- **ржлрж░рзЗржи ржХрзА рж╕рж╛ржоржЮрзНржЬрж╕рзНржп**: ржЯрзЗржмрж┐рж▓ржЧрзБрж▓рзЛрж░ ржоржзрзНржпрзЗ ржбрж╛ржЯрж╛ ржЕржЦржгрзНржбрждрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рж╛
- **рж╕рзНржЯрзЛрж░ ржЖржЗржбрж┐ ржкрзНрж░ржЪрж╛рж░**: ржкрзНрж░рждрж┐ржЯрж┐ рж▓рзЗржиржжрзЗржи ржЯрзЗржмрж┐рж▓рзЗ store_id ржЕржирзНрждрж░рзНржнрзБржХрзНржд ржХрж░рж╛
- **UUID ржкрзНрж░рж╛ржЗржорж╛рж░рж┐ ржХрзА**: ржмрж┐рждрж░ржгржХрзГржд рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЬржирзНржп ржмрж┐рж╢рзНржмржмрзНржпрж╛ржкрзА ржЕржиржирзНржп рж╢ржирж╛ржХрзНрждржХрж╛рж░рзА
- **ржЯрж╛ржЗржорж╕рзНржЯрзНржпрж╛ржорзНржк ржЯрзНрж░рзНржпрж╛ржХрж┐ржВ**: рж╕ржорж╕рзНржд ржбрж╛ржЯрж╛ ржкрж░рж┐ржмрж░рзНрждржирзЗрж░ ржЬржирзНржп ржЕржбрж┐ржЯ ржЯрзНрж░рзЗржЗрж▓

### рзи. рж░рзЛ рж▓рзЗржнрзЗрж▓ рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи

```sql
-- Enable RLS on multi-tenant tables
ALTER TABLE retail.customers ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.orders ENABLE ROW LEVEL SECURITY;
ALTER TABLE retail.order_items ENABLE ROW LEVEL SECURITY;

-- Store manager can only see their store's data
CREATE POLICY store_manager_customers ON retail.customers
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

CREATE POLICY store_manager_orders ON retail.orders
    FOR ALL TO store_managers
    USING (store_id = get_current_user_store());

-- Regional managers see multiple stores
CREATE POLICY regional_manager_orders ON retail.orders
    FOR ALL TO regional_managers
    USING (store_id = ANY(get_user_store_list()));

-- Support function for RLS context
CREATE OR REPLACE FUNCTION get_current_user_store()
RETURNS UUID AS $$
BEGIN
    RETURN current_setting('app.current_rls_user_id')::UUID;
EXCEPTION WHEN OTHERS THEN
    RETURN '00000000-0000-0000-0000-000000000000'::UUID;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

**RLS рж╕рзБржмрж┐ржзрж╛**:
- **рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржлрж┐рж▓рзНржЯрж╛рж░рж┐ржВ**: ржбрж╛ржЯрж╛ржмрзЗрж╕ ржбрж╛ржЯрж╛ ржЖржЗрж╕рзЛрж▓рзЗрж╢ржи ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзЗ
- **ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржи рж╕рж░рж▓рждрж╛**: ржЬржЯрж┐рж▓ WHERE ржХрзНрж▓ржЬрзЗрж░ ржкрзНрж░ржпрж╝рзЛржЬржи ржирзЗржЗ
- **ржбрж┐ржлрж▓рзНржЯ ржирж┐рж░рж╛ржкрждрзНрждрж╛**: ржнрзБрж▓ ржбрж╛ржЯрж╛ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕ ржХрж░рж╛ ржЕрж╕ржорзНржнржм
- **ржЕржбрж┐ржЯ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп**: ржбрж╛ржЯрж╛ ржЕрзНржпрж╛ржХрзНрж╕рзЗрж╕рзЗрж░ рж╕рзНржкрж╖рзНржЯ рж╕рзАржорж╛

### рзй. ржнрзЗржХрзНржЯрж░ рж╕рж╛рж░рзНржЪ рж╕рзНржХрж┐ржорж╛

```sql
-- Product embeddings for semantic search
CREATE TABLE retail.product_description_embeddings (
    product_id UUID PRIMARY KEY REFERENCES retail.products(product_id),
    description_embedding vector(1536),
    last_updated TIMESTAMP DEFAULT NOW()
);

-- Optimize vector similarity search
CREATE INDEX idx_product_embeddings_vector 
ON retail.product_description_embeddings 
USING ivfflat (description_embedding vector_cosine_ops);

-- Semantic search function
CREATE OR REPLACE FUNCTION search_products_by_description(
    query_embedding vector(1536),
    similarity_threshold FLOAT DEFAULT 0.7,
    max_results INTEGER DEFAULT 20
)
RETURNS TABLE(
    product_id UUID,
    name VARCHAR,
    description TEXT,
    similarity_score FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        p.product_id,
        p.name,
        p.description,
        (1 - (pde.description_embedding <=> query_embedding)) AS similarity_score
    FROM retail.products p
    JOIN retail.product_description_embeddings pde ON p.product_id = pde.product_id
    WHERE (pde.description_embedding <=> query_embedding) <= (1 - similarity_threshold)
    ORDER BY similarity_score DESC
    LIMIT max_results;
END;
$$ LANGUAGE plpgsql;
```

## ЁЯФМ ржХрж╛ржирзЗржХрж╢ржи ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ ржкрзНржпрж╛ржЯрж╛рж░рзНржи

ржжржХрзНрж╖ ржбрж╛ржЯрж╛ржмрзЗрж╕ ржХрж╛ржирзЗржХрж╢ржи ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ MCP рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕рзЗрж░ ржЬржирзНржп ржЕрждрзНржпржирзНржд ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг:

### ржХрж╛ржирзЗржХрж╢ржи ржкрзБрж▓ ржХржиржлрж┐ржЧрж╛рж░рзЗрж╢ржи

```python
class ConnectionPoolManager:
    """Manages PostgreSQL connection pools."""
    
    async def create_pool(self) -> Pool:
        """Create optimized connection pool."""
        return await asyncpg.create_pool(
            host=self.config.db_host,
            port=self.config.db_port,
            database=self.config.db_name,
            user=self.config.db_user,
            password=self.config.db_password,
            
            # Pool configuration
            min_size=2,          # Minimum connections
            max_size=10,         # Maximum connections
            max_inactive_connection_lifetime=300,  # 5 minutes
            
            # Query configuration
            command_timeout=30,   # Query timeout
            server_settings={
                "application_name": "zava-mcp-server",
                "jit": "off",          # Disable JIT for stability
                "work_mem": "4MB",     # Limit work memory
                "statement_timeout": "30s"
            }
        )
    
    async def execute_with_retry(
        self, 
        query: str, 
        params: Tuple = None,
        max_retries: int = 3
    ) -> List[Dict[str, Any]]:
        """Execute query with automatic retry logic."""
        
        for attempt in range(max_retries):
            try:
                async with self.pool.acquire() as conn:
                    if params:
                        rows = await conn.fetch(query, *params)
                    else:
                        rows = await conn.fetch(query)
                    return [dict(row) for row in rows]
                    
            except (ConnectionError, InterfaceError) as e:
                if attempt == max_retries - 1:
                    raise
                
                # Exponential backoff
                await asyncio.sleep(2 ** attempt)
                logger.warning(f"Database connection failed, retrying ({attempt + 1}/{max_retries})")
```

### рж░рж┐рж╕рзЛрж░рзНрж╕ рж▓рж╛ржЗржлрж╕рж╛ржЗржХрзЗрж▓ ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ

```python
class MCPServerManager:
    """Manages MCP server lifecycle and resources."""
    
    async def startup(self):
        """Initialize server resources."""
        # Create database connection pool
        self.db_pool = await self.pool_manager.create_pool()
        
        # Initialize AI services
        self.ai_client = await self.create_ai_client()
        
        # Setup monitoring
        self.metrics_collector = MetricsCollector()
        
        logger.info("MCP server startup complete")
    
    async def shutdown(self):
        """Cleanup server resources."""
        try:
            # Close database connections
            if self.db_pool:
                await self.db_pool.close()
            
            # Cleanup AI client
            if self.ai_client:
                await self.ai_client.close()
            
            # Flush metrics
            await self.metrics_collector.flush()
            
            logger.info("MCP server shutdown complete")
            
        except Exception as e:
            logger.error(f"Error during shutdown: {e}")
    
    async def health_check(self) -> Dict[str, str]:
        """Verify server health status."""
        status = {}
        
        # Check database connection
        try:
            async with self.db_pool.acquire() as conn:
                await conn.fetchval("SELECT 1")
            status["database"] = "healthy"
        except Exception as e:
            status["database"] = f"unhealthy: {e}"
        
        # Check AI service
        try:
            await self.ai_client.health_check()
            status["ai_service"] = "healthy"
        except Exception as e:
            status["ai_service"] = f"unhealthy: {e}"
        
        return status
```

## ЁЯЫбя╕П рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржПржмржВ рж╕рзНржерж┐рждрж┐рж╢рзАрж▓рждрж╛рж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржи

рж╢ржХрзНрждрж┐рж╢рж╛рж▓рзА рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ MCP рж╕рж╛рж░рзНржнрж╛рж░рзЗрж░ ржирж┐рж░рзНржнрж░ржпрзЛржЧрзНржп ржЕржкрж╛рж░рзЗрж╢ржи ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рзЗ:

### рж╕рзНрждрж░ржнрж┐рждрзНрждрж┐ржХ рждрзНрж░рзБржЯрж┐ ржкрзНрж░ржХрж╛рж░

```python
class MCPError(Exception):
    """Base MCP server error."""
    def __init__(self, message: str, error_code: str = "MCP_ERROR"):
        self.message = message
        self.error_code = error_code
        super().__init__(message)

class DatabaseError(MCPError):
    """Database operation errors."""
    def __init__(self, message: str, query: str = None):
        super().__init__(message, "DATABASE_ERROR")
        self.query = query

class AuthorizationError(MCPError):
    """Access control errors."""
    def __init__(self, message: str, user_id: str = None):
        super().__init__(message, "AUTHORIZATION_ERROR")
        self.user_id = user_id

class QueryTimeoutError(DatabaseError):
    """Query execution timeout."""
    def __init__(self, query: str):
        super().__init__(f"Query timeout: {query[:100]}...", query)
        self.error_code = "QUERY_TIMEOUT"

class ValidationError(MCPError):
    """Input validation errors."""
    def __init__(self, field: str, value: Any, constraint: str):
        message = f"Validation failed for {field}: {constraint}"
        super().__init__(message, "VALIDATION_ERROR")
        self.field = field
        self.value = value
```

### рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ ржорж┐ржбрж▓ржУржпрж╝рзНржпрж╛рж░

```python
@contextmanager
async def error_handling_context(operation_name: str, user_id: str = None):
    """Centralized error handling for operations."""
    start_time = time.time()
    
    try:
        yield
        
        # Success metrics
        duration = time.time() - start_time
        metrics.operation_success.labels(operation=operation_name).inc()
        metrics.operation_duration.labels(operation=operation_name).observe(duration)
        
    except ValidationError as e:
        logger.warning(f"Validation error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "validation",
            "field": e.field
        })
        metrics.operation_error.labels(operation=operation_name, type="validation").inc()
        raise
        
    except AuthorizationError as e:
        logger.warning(f"Authorization error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "authorization"
        })
        metrics.operation_error.labels(operation=operation_name, type="authorization").inc()
        raise
        
    except DatabaseError as e:
        logger.error(f"Database error in {operation_name}: {e.message}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "database",
            "query": e.query[:100] if e.query else None
        })
        metrics.operation_error.labels(operation=operation_name, type="database").inc()
        raise
        
    except Exception as e:
        logger.error(f"Unexpected error in {operation_name}: {str(e)}", extra={
            "operation": operation_name,
            "user_id": user_id,
            "error_type": "unexpected"
        }, exc_info=True)
        metrics.operation_error.labels(operation=operation_name, type="unexpected").inc()
        raise MCPError(f"Internal server error in {operation_name}")
```

## ЁЯУК ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржХрзМрж╢рж▓

### ржкрзНрж░рж╢рзНржи ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржоржирж┐ржЯрж░рж┐ржВ

```python
class QueryPerformanceMonitor:
    """Monitor and optimize query performance."""
    
    def __init__(self):
        self.slow_query_threshold = 1.0  # seconds
        self.query_stats = defaultdict(list)
    
    @contextmanager
    async def monitor_query(self, query: str, operation_type: str = "unknown"):
        """Monitor query execution time and performance."""
        start_time = time.time()
        query_hash = hashlib.md5(query.encode()).hexdigest()[:8]
        
        try:
            yield
            
            duration = time.time() - start_time
            
            # Record performance metrics
            self.query_stats[operation_type].append(duration)
            
            # Log slow queries
            if duration > self.slow_query_threshold:
                logger.warning(f"Slow query detected", extra={
                    "query_hash": query_hash,
                    "duration": duration,
                    "operation_type": operation_type,
                    "query": query[:200]
                })
            
            # Update metrics
            metrics.query_duration.labels(type=operation_type).observe(duration)
            
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"Query failed", extra={
                "query_hash": query_hash,
                "duration": duration,
                "operation_type": operation_type,
                "error": str(e)
            })
            raise
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """Generate performance summary report."""
        summary = {}
        
        for operation_type, durations in self.query_stats.items():
            if durations:
                summary[operation_type] = {
                    "count": len(durations),
                    "avg_duration": sum(durations) / len(durations),
                    "max_duration": max(durations),
                    "min_duration": min(durations),
                    "slow_queries": len([d for d in durations if d > self.slow_query_threshold])
                }
        
        return summary
```

### ржХрзНржпрж╛рж╢рж┐ржВ ржХрзМрж╢рж▓

```python
class QueryCache:
    """Intelligent query result caching."""
    
    def __init__(self, redis_url: str = None):
        self.cache = {}  # In-memory fallback
        self.redis_client = redis.Redis.from_url(redis_url) if redis_url else None
        self.cache_ttl = 300  # 5 minutes default
    
    async def get_cached_result(
        self, 
        cache_key: str, 
        query_func: Callable,
        ttl: int = None
    ) -> Any:
        """Get result from cache or execute query."""
        ttl = ttl or self.cache_ttl
        
        # Try cache first
        cached_result = await self._get_from_cache(cache_key)
        if cached_result is not None:
            metrics.cache_hit.labels(type="query").inc()
            return cached_result
        
        # Execute query
        metrics.cache_miss.labels(type="query").inc()
        result = await query_func()
        
        # Cache result
        await self._set_in_cache(cache_key, result, ttl)
        
        return result
    
    def _generate_cache_key(self, query: str, user_context: str) -> str:
        """Generate consistent cache key."""
        key_data = f"{query}:{user_context}"
        return hashlib.sha256(key_data.encode()).hexdigest()
```

## ЁЯОп ржорзВрж▓ ржмрж┐рж╖ржпрж╝ржЧрзБрж▓рзЛ

ржПржЗ рж▓рзНржпрж╛ржм рж╕ржорзНржкржирзНржи ржХрж░рж╛рж░ ржкрж░ ржЖржкржирж┐ ржмрзБржЭрждрзЗ ржкрж╛рж░ржмрзЗржи:

тЬЕ **рж╕рзНрждрж░ржпрзБржХрзНржд рж╕рзНржерж╛ржкрждрзНржп**: MCP рж╕рж╛рж░рзНржнрж╛рж░ ржбрж┐ржЬрж╛ржЗржирзЗ ржжрж╛ржпрж╝рж┐рждрзНржм ржкрзГржержХ ржХрж░рж╛рж░ ржкржжрзНржзрждрж┐  
тЬЕ **ржбрж╛ржЯрж╛ржмрзЗрж╕ ржкрзНржпрж╛ржЯрж╛рж░рзНржи**: ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНржЯ рж╕рзНржХрж┐ржорж╛ ржбрж┐ржЬрж╛ржЗржи ржПржмржВ RLS ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи  
тЬЕ **ржХрж╛ржирзЗржХрж╢ржи ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ**: ржжржХрзНрж╖ ржкрзБрж▓рж┐ржВ ржПржмржВ рж░рж┐рж╕рзЛрж░рзНрж╕ рж▓рж╛ржЗржлрж╕рж╛ржЗржХрзЗрж▓  
тЬЕ **рждрзНрж░рзБржЯрж┐ ржкрж░рж┐ржЪрж╛рж▓ржирж╛**: рж╕рзНрждрж░ржнрж┐рждрзНрждрж┐ржХ рждрзНрж░рзБржЯрж┐ ржкрзНрж░ржХрж╛рж░ ржПржмржВ рж╕рзНржерж┐рждрж┐рж╢рзАрж▓рждрж╛рж░ ржкрзНржпрж╛ржЯрж╛рж░рзНржи  
тЬЕ **ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи**: ржоржирж┐ржЯрж░рж┐ржВ, ржХрзНржпрж╛рж╢рж┐ржВ ржПржмржВ ржкрзНрж░рж╢рзНржи ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи  
тЬЕ **ржкрзНрж░рзЛржбрж╛ржХрж╢ржи ржкрзНрж░рж╕рзНрждрзБрждрж┐**: ржЗржиржлрзНрж░рж╛рж╕рзНржЯрзНрж░рж╛ржХржЪрж╛рж░ ржмрж┐рж╖ржпрж╝ ржПржмржВ ржЕржкрж╛рж░рзЗрж╢ржирж╛рж▓ ржкрзНржпрж╛ржЯрж╛рж░рзНржи  

## ЁЯЪА ржкрж░ржмрж░рзНрждрзА ржзрж╛ржк

**[рж▓рзНржпрж╛ржм рзжрзи: ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНрж╕рж┐](../02-Security/README.md)** ржПрж░ рж╕рж╛ржерзЗ ржЪрж╛рж▓рж┐ржпрж╝рзЗ ржпрж╛ржи ржпрзЗржЦрж╛ржирзЗ ржмрж┐рж╕рзНрждрж╛рж░рж┐ржд ржЖрж▓рзЛржЪржирж╛ ржХрж░рж╛ рж╣ржмрзЗ:

- рж░рзЛ рж▓рзЗржнрзЗрж▓ рж╕рж┐ржХрж┐ржЙрж░рж┐ржЯрж┐ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржирзЗрж░ ржмрж┐ржмрж░ржг
- ржкрзНрж░ржорж╛ржгрзАржХрж░ржг ржПржмржВ ржЕржирзБржорзЛржжржи ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНржЯ ржбрж╛ржЯрж╛ ржЖржЗрж╕рзЛрж▓рзЗрж╢ржи ржХрзМрж╢рж▓
- ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржЕржбрж┐ржЯ ржПржмржВ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржмрж┐ржмрзЗржЪржирж╛

## ЁЯУЪ ржЕрждрж┐рж░рж┐ржХрзНржд рж╕ржорзНржкржж

### рж╕рзНржерж╛ржкрждрзНржп ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- [Python-ржП ржХрзНрж▓рж┐ржи ржЖрж░рзНржХрж┐ржЯрзЗржХржЪрж╛рж░](https://github.com/cosmic-python/code) - Python ржЕрзНржпрж╛ржкрзНрж▓рж┐ржХрзЗрж╢ржирзЗрж░ ржЬржирзНржп рж╕рзНржерж╛ржкрждрзНржп ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- [ржбрж╛ржЯрж╛ржмрзЗрж╕ ржбрж┐ржЬрж╛ржЗржи ржкрзНржпрж╛ржЯрж╛рж░рзНржи](https://en.wikipedia.org/wiki/Database_design) - рж░рж┐рж▓рзЗрж╢ржирж╛рж▓ ржбрж╛ржЯрж╛ржмрзЗрж╕ ржбрж┐ржЬрж╛ржЗржирзЗрж░ ржирзАрждрж┐ржорж╛рж▓рж╛
- [ржорж╛ржЗржХрзНрж░рзЛрж╕рж╛рж░рзНржнрж┐рж╕ ржкрзНржпрж╛ржЯрж╛рж░рзНржи](https://microservices.io/patterns/) - рж╕рж╛рж░рзНржнрж┐рж╕ рж╕рзНржерж╛ржкрждрзНржп ржкрзНржпрж╛ржЯрж╛рж░рзНржи

### PostgreSQL ржЙржирзНржиржд ржмрж┐рж╖ржпрж╝
- [PostgreSQL ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕ ржЯрж┐ржЙржирж┐ржВ](https://wiki.postgresql.org/wiki/Performance_Optimization) - ржбрж╛ржЯрж╛ржмрзЗрж╕ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи ржЧрж╛ржЗржб
- [ржХрж╛ржирзЗржХрж╢ржи ржкрзБрж▓рж┐ржВ рж╕рзЗрж░рж╛ ржЕржирзБрж╢рзАрж▓ржи](https://www.postgresql.org/docs/current/runtime-config-connection.html) - ржХрж╛ржирзЗржХрж╢ржи ржорзНржпрж╛ржирзЗржЬржорзЗржирзНржЯ
- [ржкрзНрж░рж╢рзНржи ржкрж░рж┐ржХрж▓рзНржкржирж╛ ржПржмржВ ржЕржкрзНржЯрж┐ржорж╛ржЗржЬрзЗрж╢ржи](https://www.postgresql.org/docs/current/planner-optimizer.html) - ржкрзНрж░рж╢рзНржи ржкрж╛рж░ржлрж░ржорзНржпрж╛ржирзНрж╕

### Python ржЕрзНржпрж╛рж╕рж┐ржЩрзНржХ ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- [AsyncIO рж╕рзЗрж░рж╛ ржЕржирзБрж╢рзАрж▓ржи](https://docs.python.org/3/library/asyncio.html) - ржЕрзНржпрж╛рж╕рж┐ржЩрзНржХ ржкрзНрж░рзЛржЧрзНрж░рж╛ржорж┐ржВ ржкрзНржпрж╛ржЯрж╛рж░рзНржи
- [FastAPI рж╕рзНржерж╛ржкрждрзНржп](https://fastapi.tiangolo.com/advanced/) - ржЖржзрзБржирж┐ржХ Python ржУржпрж╝рзЗржм рж╕рзНржерж╛ржкрждрзНржп
- [Pydantic ржоржбрзЗрж▓](https://pydantic-docs.helpmanual.io/) - ржбрж╛ржЯрж╛ ржпрж╛ржЪрж╛ржЗ ржПржмржВ рж╕рж┐рж░рж┐ржпрж╝рж╛рж▓рж╛ржЗржЬрзЗрж╢ржи

---

**ржкрж░ржмрж░рзНрждрзА**: ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржкрзНржпрж╛ржЯрж╛рж░рзНржи ржЕржирзНржмрзЗрж╖ржг ржХрж░рждрзЗ ржкрзНрж░рж╕рзНрждрзБржд? ржЪрж╛рж▓рж┐ржпрж╝рзЗ ржпрж╛ржи [рж▓рзНржпрж╛ржм рзжрзи: ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржПржмржВ ржорж╛рж▓рзНржЯрж┐-ржЯрзЗржирзНржпрж╛ржирзНрж╕рж┐](../02-Security/README.md)

---

**ржЕрж╕рзНржмрзАржХрзГрждрж┐**:  
ржПржЗ ржиржерж┐ржЯрж┐ AI ржЕржирзБржмрж╛ржж ржкрж░рж┐рж╖рзЗржмрж╛ [Co-op Translator](https://github.com/Azure/co-op-translator) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржЕржирзБржмрж╛ржж ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЖржорж░рж╛ ржпржерж╛рж╕рж╛ржзрзНржп рж╕ржарж┐ржХрждрж╛ ржирж┐рж╢рзНржЪрж┐ржд ржХрж░рж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рж┐, рждржмрзЗ ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржоржирзЗ рж░рж╛ржЦржмрзЗржи ржпрзЗ рж╕рзНржмржпрж╝ржВржХрзНрж░рж┐ржпрж╝ ржЕржирзБржмрж╛ржжрзЗ рждрзНрж░рзБржЯрж┐ ржмрж╛ ржЕрж╕ржЩрзНржЧрждрж┐ ржерж╛ржХрждрзЗ ржкрж╛рж░рзЗред ржорзВрж▓ ржнрж╛рж╖рж╛ржпрж╝ ржерж╛ржХрж╛ ржиржерж┐ржЯрж┐ржХрзЗ ржкрзНрж░рж╛ржорж╛ржгрж┐ржХ ржЙрзОрж╕ рж╣рж┐рж╕рзЗржмрзЗ ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рж╛ ржЙржЪрж┐рждред ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг рждржерзНржпрзЗрж░ ржЬржирзНржп, ржкрзЗрж╢рж╛ржжрж╛рж░ ржорж╛ржиржм ржЕржирзБржмрж╛ржж рж╕рзБржкрж╛рж░рж┐рж╢ ржХрж░рж╛ рж╣ржпрж╝ред ржПржЗ ржЕржирзБржмрж╛ржж ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржлрж▓рзЗ ржХрзЛржирзЛ ржнрзБрж▓ ржмрзЛржЭрж╛ржмрзБржЭрж┐ ржмрж╛ ржнрзБрж▓ ржмрзНржпрж╛ржЦрзНржпрж╛ рж╣рж▓рзЗ ржЖржорж░рж╛ ржжрж╛ржпрж╝ржмржжрзНржз ржерж╛ржХржм ржирж╛ред