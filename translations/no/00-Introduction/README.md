<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "25a94c681cf43612ff394d8cf78a74de",
  "translation_date": "2025-05-27T16:06:35+00:00",
  "source_file": "00-Introduction/README.md",
  "language_code": "no"
}
-->
# Introduksjon til Model Context Protocol (MCP): Hvorfor det er viktig for skalerbare AI-applikasjoner

Generative AI-applikasjoner er et stort steg fremover, da de ofte lar brukeren samhandle med appen ved hjelp av naturlige sprÃ¥kkommandoer. Men etter hvert som mer tid og ressurser investeres i slike apper, vil du sikre at det er enkelt Ã¥ integrere funksjonalitet og ressurser pÃ¥ en mÃ¥te som gjÃ¸r det lett Ã¥ utvide, at appen kan hÃ¥ndtere flere modeller samtidig, og takle ulike modellspesifikke detaljer. Kort sagt, det er lett Ã¥ komme i gang med Ã¥ bygge Gen AI-apper, men nÃ¥r de vokser og blir mer komplekse, mÃ¥ du begynne Ã¥ definere en arkitektur og sannsynligvis bruke en standard for Ã¥ sikre at appene dine bygges pÃ¥ en konsistent mÃ¥te. Her kommer MCP inn for Ã¥ organisere ting og tilby en standard.

---

## **ğŸ” Hva er Model Context Protocol (MCP)?**

**Model Context Protocol (MCP)** er et **Ã¥pent, standardisert grensesnitt** som gjÃ¸r det mulig for store sprÃ¥kmodeller (LLMs) Ã¥ samhandle sÃ¸mlÃ¸st med eksterne verktÃ¸y, API-er og datakilder. Det gir en konsekvent arkitektur som forbedrer AI-modellers funksjonalitet utover treningsdataene, og muliggjÃ¸r smartere, skalerbare og mer responsive AI-systemer.

---

## **ğŸ¯ Hvorfor standardisering i AI er viktig**

Etter hvert som generative AI-applikasjoner blir mer komplekse, er det viktig Ã¥ ta i bruk standarder som sikrer **skalerbarhet, utvidbarhet** og **vedlikeholdbarhet**. MCP lÃ¸ser disse behovene ved Ã¥:

- Samle modell-verktÃ¸y-integrasjoner
- Redusere skjÃ¸re, engangslÃ¸sninger
- Tillate at flere modeller kan eksistere i samme Ã¸kosystem

---

## **ğŸ“š LÃ¦ringsmÃ¥l**

Etter Ã¥ ha lest denne artikkelen vil du kunne:

- Definere **Model Context Protocol (MCP)** og forstÃ¥ bruksomrÃ¥dene
- ForstÃ¥ hvordan MCP standardiserer kommunikasjon mellom modell og verktÃ¸y
- Identifisere de viktigste komponentene i MCP-arkitekturen
- Utforske virkelige bruksomrÃ¥der for MCP i bedrifts- og utviklingsmiljÃ¸er

---

## **ğŸ’¡ Hvorfor Model Context Protocol (MCP) er en banebryter**

### **ğŸ”— MCP lÃ¸ser fragmentering i AI-interaksjoner**

FÃ¸r MCP krevde integrasjon av modeller med verktÃ¸y:

- Egen kode for hvert verktÃ¸y-modell-par
- Ikke-standardiserte API-er for hver leverandÃ¸r
- Hyppige brudd ved oppdateringer
- DÃ¥rlig skalerbarhet med flere verktÃ¸y

### **âœ… Fordeler med MCP-standardisering**

| **Fordel**               | **Beskrivelse**                                                               |
|--------------------------|-------------------------------------------------------------------------------|
| Interoperabilitet        | LLM-er fungerer sÃ¸mlÃ¸st med verktÃ¸y fra ulike leverandÃ¸rer                    |
| Konsistens               | Ensartet oppfÃ¸rsel pÃ¥ tvers av plattformer og verktÃ¸y                         |
| Gjenbrukbarhet           | VerktÃ¸y bygget Ã©n gang kan brukes pÃ¥ tvers av prosjekter og systemer          |
| Raskere utvikling        | Reduserer utviklingstid ved Ã¥ bruke standardiserte, plug-and-play-grensesnitt |

---

## **ğŸ§± HÃ¸y-nivÃ¥ oversikt over MCP-arkitektur**

MCP fÃ¸lger en **klient-server-modell**, der:

- **MCP Hosts** kjÃ¸rer AI-modellene
- **MCP Clients** initierer forespÃ¸rsler
- **MCP Servers** leverer kontekst, verktÃ¸y og funksjonalitet

### **NÃ¸kkelkomponenter:**

- **Ressurser** â€“ Statisk eller dynamisk data for modellene  
- **Prompter** â€“ ForhÃ¥ndsdefinerte arbeidsflyter for styrt generering  
- **VerktÃ¸y** â€“ UtfÃ¸rbare funksjoner som sÃ¸k, beregninger  
- **Sampling** â€“ Agent-lignende oppfÃ¸rsel via rekursive interaksjoner

---

## Hvordan MCP-servere fungerer

MCP-servere opererer pÃ¥ fÃ¸lgende mÃ¥te:

- **ForespÃ¸rselsflyt**:  
    1. MCP Client sender en forespÃ¸rsel til AI-modellen som kjÃ¸rer i en MCP Host.  
    2. AI-modellen identifiserer nÃ¥r den trenger eksterne verktÃ¸y eller data.  
    3. Modellen kommuniserer med MCP Serveren via det standardiserte protokoll.

- **MCP Server-funksjonalitet**:  
    - VerktÃ¸yregister: Holder en katalog over tilgjengelige verktÃ¸y og deres funksjoner.  
    - Autentisering: Verifiserer tilgangstillatelser for verktÃ¸y.  
    - ForespÃ¸rselsbehandler: Behandler innkommende verktÃ¸yforespÃ¸rsler fra modellen.  
    - Svarformatterer: Strukturere verktÃ¸yutdata i et format modellen kan forstÃ¥.

- **VerktÃ¸ykjÃ¸ring**:  
    - Serveren sender forespÃ¸rsler til passende eksterne verktÃ¸y  
    - VerktÃ¸yene utfÃ¸rer sine spesialiserte funksjoner (sÃ¸k, beregning, databaseforespÃ¸rsler osv.)  
    - Resultater returneres til modellen i et konsistent format.

- **FullfÃ¸ring av svar**:  
    - AI-modellen inkorporerer verktÃ¸yutdata i svaret sitt.  
    - Det endelige svaret sendes tilbake til klientapplikasjonen.

```mermaid
graph TD
    A[AI Model in MCP Host] <-->|MCP Protocol| B[MCP Server]
    B <-->|Tool Interface| C[Tool 1: Web Search]
    B <-->|Tool Interface| D[Tool 2: Calculator]
    B <-->|Tool Interface| E[Tool 3: Database Access]
    B <-->|Tool Interface| F[Tool 4: File System]
    
    Client[MCP Client/Application] -->|Sends Request| A
    A -->|Returns Response| Client
    
    subgraph "MCP Server Components"
        B
        G[Tool Registry]
        H[Authentication]
        I[Request Handler]
        J[Response Formatter]
    end
    
    B <--> G
    B <--> H
    B <--> I
    B <--> J
    
    style A fill:#f9d5e5,stroke:#333,stroke-width:2px
    style B fill:#eeeeee,stroke:#333,stroke-width:2px
    style Client fill:#d5e8f9,stroke:#333,stroke-width:2px
    style C fill:#c2f0c2,stroke:#333,stroke-width:1px
    style D fill:#c2f0c2,stroke:#333,stroke-width:1px
    style E fill:#c2f0c2,stroke:#333,stroke-width:1px
    style F fill:#c2f0c2,stroke:#333,stroke-width:1px    
```

## ğŸ‘¨â€ğŸ’» Hvordan bygge en MCP-server (med eksempler)

MCP-servere lar deg utvide LLM-funksjonalitet ved Ã¥ tilby data og funksjoner.

Klar til Ã¥ prÃ¸ve? Her er eksempler pÃ¥ hvordan du lager en enkel MCP-server i ulike sprÃ¥k:

- **Python-eksempel**: https://github.com/modelcontextprotocol/python-sdk

- **TypeScript-eksempel**: https://github.com/modelcontextprotocol/typescript-sdk

- **Java-eksempel**: https://github.com/modelcontextprotocol/java-sdk

- **C#/.NET-eksempel**: https://github.com/modelcontextprotocol/csharp-sdk

## ğŸŒ Virkelige bruksomrÃ¥der for MCP

MCP muliggjÃ¸r et bredt spekter av applikasjoner ved Ã¥ utvide AI-funksjonalitet:

| **Applikasjon**             | **Beskrivelse**                                                                |
|----------------------------|--------------------------------------------------------------------------------|
| Bedriftsdata-integrasjon    | Koble LLM-er til databaser, CRM-systemer eller interne verktÃ¸y                 |
| Agentbaserte AI-systemer    | MuliggjÃ¸r autonome agenter med verktÃ¸ystÃ¸tte og beslutningsflyt                |
| Multimodale applikasjoner   | Kombiner tekst-, bilde- og lydverktÃ¸y i en samlet AI-app                       |
| Sanntids data-integrasjon   | Hent inn live data i AI-interaksjoner for mer nÃ¸yaktige og oppdaterte svar    |

### ğŸ§  MCP = Universell standard for AI-interaksjoner

Model Context Protocol (MCP) fungerer som en universell standard for AI-interaksjoner, pÃ¥ samme mÃ¥te som USB-C standardiserte fysiske tilkoblinger for enheter. I AI-verdenen gir MCP et konsekvent grensesnitt som gjÃ¸r at modeller (klienter) kan integreres sÃ¸mlÃ¸st med eksterne verktÃ¸y og dataleverandÃ¸rer (servere). Dette eliminerer behovet for ulike, egendefinerte protokoller for hver API eller datakilde.

Under MCP fÃ¸lger et MCP-kompatibelt verktÃ¸y (kalt MCP-server) en felles standard. Disse serverne kan liste opp verktÃ¸yene eller handlingene de tilbyr, og utfÃ¸re dem nÃ¥r en AI-agent ber om det. AI-agent-plattformer som stÃ¸tter MCP kan oppdage tilgjengelige verktÃ¸y fra serverne og kalle dem via denne standardprotokollen.

### ğŸ’¡ Legger til rette for kunnskaps-tilgang

I tillegg til Ã¥ tilby verktÃ¸y, legger MCP ogsÃ¥ til rette for tilgang til kunnskap. Det gjÃ¸r det mulig for applikasjoner Ã¥ gi kontekst til store sprÃ¥kmodeller (LLMs) ved Ã¥ koble dem til ulike datakilder. For eksempel kan en MCP-server representere et selskaps dokumentarkiv, slik at agenter kan hente relevant informasjon ved behov. En annen server kan hÃ¥ndtere spesifikke handlinger som Ã¥ sende e-post eller oppdatere poster. Fra agentens perspektiv er dette bare verktÃ¸y den kan bruke â€” noen verktÃ¸y returnerer data (kunnskapskontekst), mens andre utfÃ¸rer handlinger. MCP hÃ¥ndterer begge effektivt.

En agent som kobler til en MCP-server lÃ¦rer automatisk om serverens tilgjengelige funksjoner og data gjennom et standardisert format. Denne standardiseringen muliggjÃ¸r dynamisk tilgjengelighet av verktÃ¸y. For eksempel, nÃ¥r du legger til en ny MCP-server i agentens system, blir funksjonene umiddelbart tilgjengelige uten behov for ekstra tilpasning av agentens instruksjoner.

Denne strÃ¸mlinjeformede integrasjonen fÃ¸lger flyten vist i mermaid-diagrammet, hvor servere leverer bÃ¥de verktÃ¸y og kunnskap, og sikrer sÃ¸mlÃ¸st samarbeid mellom systemer.

### ğŸ‘‰ Eksempel: Skalerbar agentlÃ¸sning

```mermaid
graph TD
    User -->|Prompt| LLM
    LLM -->|Response| User
    LLM -->|MCP| ServerA
    LLM -->|MCP| ServerB
    ServerA -->|Universal connector| ServerB
    ServerA --> KnowledgeA
    ServerA --> ToolsA
    ServerB --> KnowledgeB
    ServerB --> ToolsB

    subgraph Server A
        KnowledgeA[Knowledge]
        ToolsA[Tools]
    end

    subgraph Server B
        KnowledgeB[Knowledge]
        ToolsB[Tools]
    end
```

### ğŸ”„ Avanserte MCP-scenarier med klient-side LLM-integrasjon

I tillegg til grunnleggende MCP-arkitektur finnes det avanserte scenarier hvor bÃ¥de klient og server inneholder LLM-er, noe som muliggjÃ¸r mer sofistikerte interaksjoner:

```mermaid
sequenceDiagram
    autonumber
    actor User as ğŸ‘¤ User
    participant ClientApp as ğŸ–¥ï¸ Client App
    participant ClientLLM as ğŸ§  Client LLM
    participant Server1 as ğŸ”§ MCP Server 1
    participant Server2 as ğŸ“š MCP Server 2
    participant ServerLLM as ğŸ¤– Server LLM
    
    %% Discovery Phase
    rect rgb(220, 240, 255)
        Note over ClientApp, Server2: TOOL DISCOVERY PHASE
        ClientApp->>+Server1: Request available tools/resources
        Server1-->>-ClientApp: Return tool list (JSON)
        ClientApp->>+Server2: Request available tools/resources
        Server2-->>-ClientApp: Return tool list (JSON)
        Note right of ClientApp: Store combined tool<br/>catalog locally
    end
    
    %% User Interaction
    rect rgb(255, 240, 220)
        Note over User, ClientLLM: USER INTERACTION PHASE
        User->>+ClientApp: Enter natural language prompt
        ClientApp->>+ClientLLM: Forward prompt + tool catalog
        ClientLLM->>-ClientLLM: Analyze prompt & select tools
    end
    
    %% Scenario A: Direct Tool Calling
    alt Direct Tool Calling
        rect rgb(220, 255, 220)
            Note over ClientApp, Server1: SCENARIO A: DIRECT TOOL CALLING
            ClientLLM->>+ClientApp: Request tool execution
            ClientApp->>+Server1: Execute specific tool
            Server1-->>-ClientApp: Return results
            ClientApp->>+ClientLLM: Process results
            ClientLLM-->>-ClientApp: Generate response
            ClientApp-->>-User: Display final answer
        end
    
    %% Scenario B: Feature Negotiation (VS Code style)
    else Feature Negotiation (VS Code style)
        rect rgb(255, 220, 220)
            Note over ClientApp, ServerLLM: SCENARIO B: FEATURE NEGOTIATION
            ClientLLM->>+ClientApp: Identify needed capabilities
            ClientApp->>+Server2: Negotiate features/capabilities
            Server2->>+ServerLLM: Request additional context
            ServerLLM-->>-Server2: Provide context
            Server2-->>-ClientApp: Return available features
            ClientApp->>+Server2: Call negotiated tools
            Server2-->>-ClientApp: Return results
            ClientApp->>+ClientLLM: Process results
            ClientLLM-->>-ClientApp: Generate response
            ClientApp-->>-User: Display final answer
        end
    end
```

## ğŸ” Praktiske fordeler med MCP

Her er de praktiske fordelene ved Ã¥ bruke MCP:

- **Oppdatert informasjon**: Modeller kan fÃ¥ tilgang til fersk informasjon utover treningsdataene sine  
- **Utvidet funksjonalitet**: Modeller kan bruke spesialiserte verktÃ¸y for oppgaver de ikke er trent pÃ¥  
- **Reduserte hallusinasjoner**: Eksterne datakilder gir faktabasert grunnlag  
- **Personvern**: Sensitiv data kan holdes innen sikre miljÃ¸er i stedet for Ã¥ vÃ¦re innebygd i prompts

## ğŸ“Œ Viktige punkter Ã¥ huske

Her er hovedpunktene for bruk av MCP:

- **MCP** standardiserer hvordan AI-modeller samhandler med verktÃ¸y og data  
- Fremmer **utvidbarhet, konsistens og interoperabilitet**  
- MCP bidrar til Ã¥ **redusere utviklingstid, forbedre pÃ¥litelighet og utvide modellfunksjonalitet**  
- Klient-server-arkitekturen **muliggjÃ¸r fleksible, utvidbare AI-applikasjoner**

## ğŸ§  Ã˜velse

Tenk pÃ¥ en AI-applikasjon du er interessert i Ã¥ bygge.

- Hvilke **eksterne verktÃ¸y eller data** kan forbedre dens funksjonalitet?  
- Hvordan kan MCP gjÃ¸re integrasjonen **enklere og mer pÃ¥litelig?**

## Tilleggsressurser

- [MCP GitHub Repository](https://github.com/modelcontextprotocol)

## Hva skjer videre

Neste: [Kapittel 1: Kjernebegreper](/01-CoreConcepts/README.md)

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved bruk av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nÃ¸yaktighet, vÃ¦r oppmerksom pÃ¥ at automatiserte oversettelser kan inneholde feil eller unÃ¸yaktigheter. Det opprinnelige dokumentet pÃ¥ originalsprÃ¥ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforstÃ¥elser eller feiltolkninger som oppstÃ¥r fra bruken av denne oversettelsen.